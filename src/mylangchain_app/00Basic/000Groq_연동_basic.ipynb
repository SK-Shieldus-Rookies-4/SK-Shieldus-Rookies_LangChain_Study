{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello LangChain\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello LangChain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gsk_oohxJ\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI \n",
    "\n",
    "# load_dotenv(dotenv_path='.env')\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:9])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.prompts.chat.ChatPromptTemplate'>\n",
      "input_variables=['input'] input_types={} partial_variables={} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='ë‹¹ì‹ ì€ ê°œë°œìì…ë‹ˆë‹¤.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "# prompt + llm + output \n",
    "\n",
    "# prompt\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [ (\"system\", \"ë‹¹ì‹ ì€ ê°œë°œìì…ë‹ˆë‹¤.\") , \n",
    "     (\"user\", \"{input}\") ]\n",
    ")\n",
    "print(type(prompt))\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "System: ë‹¹ì‹ ì€ ê°œë°œìì…ë‹ˆë‹¤.\n",
      "Human: íŒŒì´ì¬ì€ ë¬´ì—‡ì¸ê°€ìš”? ìì„¸í•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”\n"
     ]
    }
   ],
   "source": [
    "prompt_text = prompt.format(input=\"íŒŒì´ì¬ì€ ë¬´ì—‡ì¸ê°€ìš”? ìì„¸í•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”\")\n",
    "print(type(prompt_text))\n",
    "print(prompt_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_openai.chat_models.base.ChatOpenAI'>\n",
      "client=<openai.resources.chat.completions.completions.Completions object at 0x1550bd5b0> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x1550bf230> root_client=<openai.OpenAI object at 0x1550bcb00> root_async_client=<openai.AsyncOpenAI object at 0x1550bf360> model_name='openai/gpt-oss-120b' temperature=0.7 model_kwargs={} openai_api_key=SecretStr('**********') openai_api_base='https://api.groq.com/openai/v1'\n"
     ]
    }
   ],
   "source": [
    "#llm = ChatOpenAI(api_key=OPENAI_API_KEY, model_name=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "# Groq APIë¥¼ ì‚¬ìš©í•˜ëŠ” ChatOpenAI ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
    "llm = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    #model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    # model=\"moonshotai/kimi-k2-instruct-0905\",\n",
    "    model=\"openai/gpt-oss-120b\",\n",
    "    temperature=0.7\n",
    ")\n",
    "print(type(llm))\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "ì‘ë‹µ: ## íŒŒì´ì¬(Python)ì´ë€?\n",
      "\n",
      "íŒŒì´ì¬ì€ **ê³ ìˆ˜ì¤€(high-level), ì¸í„°í”„ë¦¬í„°í˜•(interpreted), ë™ì  íƒ€ì´í•‘(dynamic typing)** ì–¸ì–´ì´ë©°, **ì½”ë“œ ê°€ë…ì„±**ê³¼ **ìƒì‚°ì„±**ì„ ìµœìš°ì„ ìœ¼ë¡œ ì„¤ê³„ëœ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì…ë‹ˆë‹¤. 1991ë…„ ë„¤ëœë€ë“œì˜ í”„ë¡œê·¸ë˜ë¨¸ **ê·€ë„ ë°˜ ë¡œì¸(Guido van Rossum)**ì´ ì²˜ìŒ ë°œí‘œí–ˆìœ¼ë©°, í˜„ì¬ëŠ” ì „ ì„¸ê³„ ê°œë°œì ì»¤ë®¤ë‹ˆí‹°ì™€ ê¸°ì—…ì—ì„œ í­ë„“ê²Œ ì‚¬ìš©ë˜ê³  ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "---\n",
      "\n",
      "## 1. íŒŒì´ì¬ì˜ ì£¼ìš” íŠ¹ì§•\n",
      "\n",
      "| íŠ¹ì§• | ì„¤ëª… |\n",
      "|------|------|\n",
      "| **ê°€ë…ì„± ë†’ì€ ë¬¸ë²•** | ë“¤ì—¬ì“°ê¸°(indent) ê¸°ë°˜ ë¸”ë¡ êµ¬ì¡°, ìµœì†Œí•œì˜ êµ¬ë¬¸(syntax)ìœ¼ë¡œ ë³µì¡í•œ ë¡œì§ì„ ê°„ê²°í•˜ê²Œ í‘œí˜„ |\n",
      "| **ë™ì  íƒ€ì´í•‘** | ë³€ìˆ˜ ì„ ì–¸ ì‹œ íƒ€ì…ì„ ëª…ì‹œí•˜ì§€ ì•Šì•„ë„ ë˜ë©°, ì‹¤í–‰ ì‹œì ì— íƒ€ì…ì´ ê²°ì • |\n",
      "| **ì¸í„°í”„ë¦¬í„° ì–¸ì–´** | ì½”ë“œë¥¼ í•œ ì¤„ì”© ë°”ë¡œ ì‹¤í–‰(ì»´íŒŒì¼ ë‹¨ê³„ ì—†ì´) â†’ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ì™€ í”„ë¡œí† íƒ€ì´í•‘ ê°€ëŠ¥ |\n",
      "| **ê´‘ë²”ìœ„í•œ í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬** | â€œë°°í„°ë¦¬ í¬í•¨(batteriesâ€‘included)â€ ì² í•™ì— ë”°ë¼ íŒŒì¼ I/O, ë„¤íŠ¸ì›Œí‚¹, ì›¹, ë°ì´í„°ë² ì´ìŠ¤, ì•”í˜¸í™” ë“± ë‹¤ì–‘í•œ ê¸°ëŠ¥ì„ ê¸°ë³¸ ì œê³µ |\n",
      "| **ë©€í‹°íŒ¨ëŸ¬ë‹¤ì„ ì§€ì›** | ì ˆì°¨ì , ê°ì²´ì§€í–¥, í•¨ìˆ˜í˜• í”„ë¡œê·¸ë˜ë°ì„ ëª¨ë‘ ì§€ì› |\n",
      "| **í”Œë«í¼ ë…ë¦½ì„±** | Windows, macOS, Linux, ê·¸ë¦¬ê³  ëª¨ë°”ì¼/ì„ë² ë””ë“œ í™˜ê²½ê¹Œì§€ ë‹¤ì–‘í•œ OSì—ì„œ ë™ì¼í•˜ê²Œ ì‹¤í–‰ |\n",
      "| **í™•ì¥ì„±** | C/C++ ë¡œ ì‘ì„±ëœ ëª¨ë“ˆ(Cython, CPython)ì´ë‚˜ Java ê¸°ë°˜ ëª¨ë“ˆ(Jython) ë“±ìœ¼ë¡œ ì„±ëŠ¥ì„ ë³´ê°• ê°€ëŠ¥ |\n",
      "| **í’ë¶€í•œ ì„œë“œíŒŒí‹° ìƒíƒœê³„** | PyPI(Python Package Index) ì— 30ë§Œ ê°œê°€ ë„˜ëŠ” íŒ¨í‚¤ì§€ ì œê³µ (ì˜ˆ: NumPy, pandas, TensorFlow, Django ë“±) |\n",
      "\n",
      "---\n",
      "\n",
      "## 2. íŒŒì´ì¬ì˜ ì—­ì‚¬\n",
      "\n",
      "| ì—°ë„ | ì‚¬ê±´ |\n",
      "|------|------|\n",
      "| **1980ë…„ëŒ€ í›„ë°˜** | ê·€ë„ ë°˜ ë¡œì¸ì´ â€œABCâ€ ì–¸ì–´ì˜ ê²½í—˜ì„ ë°”íƒ•ìœ¼ë¡œ ìƒˆë¡œìš´ ì–¸ì–´ ì„¤ê³„ ì‹œì‘ |\n",
      "| **1991ë…„** | ì²« ë²ˆì§¸ ê³µê°œ ë²„ì „ **Python 0.9.0** ë°œí‘œ (ì˜ˆì™¸ ì²˜ë¦¬, ëª¨ë“ˆ ì‹œìŠ¤í…œ ë“± ê¸°ë³¸ ê¸°ëŠ¥ í¬í•¨) |\n",
      "| **1994ë…„** | **Python 1.0** ì¶œì‹œ â€“ ëª¨ë“ˆ, í•¨ìˆ˜, ì˜ˆì™¸ ì²˜ë¦¬ ë“± ì •ì‹ ê¸°ëŠ¥ ì œê³µ |\n",
      "| **2000ë…„** | **Python 2.0** ë°œí‘œ â€“ ë¦¬ìŠ¤íŠ¸ ì»´í”„ë¦¬í—¨ì…˜, ê°€ë¹„ì§€ ì»¬ë ‰ì…˜, ìœ ë‹ˆì½”ë“œ ì§€ì› ë“± |\n",
      "| **2008ë…„** | **Python 3.0** ë°œí‘œ â€“ ì–¸ì–´ ìì²´ë¥¼ ì •ë¦¬Â·ì •ë¹„ (ë¬¸ìì—´/ë°”ì´íŠ¸ êµ¬ë¶„, print í•¨ìˆ˜í™” ë“±) |\n",
      "| **2020ë…„** | **Python 3.9** ì¶œì‹œ â€“ ìƒˆë¡œìš´ ë¬¸ë²•(`:=` ì—°ì‚°ì ë“±)ê³¼ ì„±ëŠ¥ ê°œì„  |\n",
      "| **2023ë…„** | **Python 3.12** ì¶œì‹œ â€“ íŒ¨í„´ ë§¤ì¹­ ê°•í™”, ì¸í„°í”„ë¦¬í„° ìµœì í™” ë“± |\n",
      "| **í˜„ì¬** | í™œë°œí•œ ì»¤ë®¤ë‹ˆí‹°ì™€ ì—°ê°„ 2~3ë²ˆì˜ ì£¼ìš” ë¦´ë¦¬ì¦ˆê°€ ì§„í–‰ ì¤‘ (2025ë…„ í˜„ì¬ ìµœì‹  ë²„ì „ì€ 3.13.x) |\n",
      "\n",
      "> **í•µì‹¬ í¬ì¸íŠ¸**: Python 2ì™€ 3ëŠ” í˜¸í™˜ì„±ì´ ë‚®ì•„ Python 2ëŠ” 2020ë…„ ê³µì‹ ì§€ì›ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ìƒˆ í”„ë¡œì íŠ¸ëŠ” ë°˜ë“œì‹œ Python 3ë¥¼ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.\n",
      "\n",
      "---\n",
      "\n",
      "## 3. íŒŒì´ì¬ì´ ë„ë¦¬ ì“°ì´ëŠ” ë¶„ì•¼\n",
      "\n",
      "| ë¶„ì•¼ | í™œìš© ì˜ˆì‹œ |\n",
      "|------|-----------|\n",
      "| **ì›¹ ê°œë°œ** | Django, Flask, FastAPI ë“± í”„ë ˆì„ì›Œí¬ë¥¼ ì´ìš©í•œ ì„œë²„Â·API êµ¬í˜„ |\n",
      "| **ë°ì´í„° ê³¼í•™Â·ë¶„ì„** | NumPy, pandas, Matplotlib, Seaborn ë“±ì„ í†µí•œ ë°ì´í„° ì „ì²˜ë¦¬Â·ì‹œê°í™” |\n",
      "| **ë¨¸ì‹ ëŸ¬ë‹Â·ë”¥ëŸ¬ë‹** | scikit-learn, TensorFlow, PyTorch, Keras ë“±ìœ¼ë¡œ ëª¨ë¸ êµ¬ì¶•Â·í•™ìŠµ |\n",
      "| **ìë™í™”Â·ìŠ¤í¬ë¦½íŠ¸** | ì‹œìŠ¤í…œ ê´€ë¦¬, íŒŒì¼ ì²˜ë¦¬, í…ŒìŠ¤íŠ¸ ìë™í™”, ì›¹ ìŠ¤í¬ë˜í•‘(BeautifulSoup, Selenium) |\n",
      "| **ê³¼í•™Â·ê³µí•™** | SciPy, SymPy, Jupyter Notebookì„ ì´ìš©í•œ ì‹œë®¬ë ˆì´ì…˜Â·ì—°êµ¬ |\n",
      "| **ê²Œì„ ê°œë°œ** | Pygame, Panda3D ë“±ìœ¼ë¡œ ê°„ë‹¨í•œ 2D/3D ê²Œì„ ì œì‘ |\n",
      "| **ì„ë² ë””ë“œÂ·IoT** | MicroPython, CircuitPythonìœ¼ë¡œ ë§ˆì´í¬ë¡œì»¨íŠ¸ë¡¤ëŸ¬ í”„ë¡œê·¸ë˜ë° |\n",
      "| **êµìœ¡** | ë¬¸ë²•ì´ ì§ê´€ì ì´ë¼ í”„ë¡œê·¸ë˜ë° ì…ë¬¸ êµìœ¡ì— ìµœì  |\n",
      "\n",
      "---\n",
      "\n",
      "## 4. íŒŒì´ì¬ ê¸°ë³¸ ë¬¸ë²• ì†Œê°œ\n",
      "\n",
      "### 4.1 ë³€ìˆ˜ì™€ ìë£Œí˜•\n",
      "\n",
      "```python\n",
      "# ì •ìˆ˜, ì‹¤ìˆ˜, ë¬¸ìì—´, ë¶ˆë¦¬ì–¸\n",
      "a = 10          # int\n",
      "b = 3.14        # float\n",
      "name = \"Alice\" # str\n",
      "flag = True    # bool\n",
      "```\n",
      "\n",
      "### 4.2 ì»¬ë ‰ì…˜(ì‹œí€€ìŠ¤Â·ë§¤í•‘)\n",
      "\n",
      "```python\n",
      "# ë¦¬ìŠ¤íŠ¸, íŠœí”Œ, ë”•ì…”ë„ˆë¦¬, ì§‘í•©\n",
      "numbers = [1, 2, 3, 4]          # list\n",
      "coords  = (10, 20)              # tuple (ë¶ˆë³€)\n",
      "person  = {\"name\": \"Bob\", \"age\": 30}  # dict\n",
      "unique  = {1, 2, 3}             # set\n",
      "```\n",
      "\n",
      "### 4.3 ì œì–´ íë¦„\n",
      "\n",
      "```python\n",
      "# if-elif-else\n",
      "if a > 0:\n",
      "    print(\"ì–‘ìˆ˜\")\n",
      "elif a == 0:\n",
      "    print(\"0\")\n",
      "else:\n",
      "    print(\"ìŒìˆ˜\")\n",
      "\n",
      "# for ë£¨í”„ (ë¦¬ìŠ¤íŠ¸ ìˆœíšŒ)\n",
      "for num in numbers:\n",
      "    print(num * 2)\n",
      "\n",
      "# while ë£¨í”„\n",
      "i = 0\n",
      "while i < 5:\n",
      "    print(i)\n",
      "    i += 1\n",
      "```\n",
      "\n",
      "### 4.4 í•¨ìˆ˜ ì •ì˜ì™€ ëŒë‹¤\n",
      "\n",
      "```python\n",
      "def add(x, y):\n",
      "    \"\"\"ë‘ ìˆ«ìì˜ í•©ì„ ë°˜í™˜í•©ë‹ˆë‹¤.\"\"\"\n",
      "    return x + y\n",
      "\n",
      "# í˜¸ì¶œ\n",
      "result = add(3, 5)   # 8\n",
      "\n",
      "# ëŒë‹¤ í•¨ìˆ˜ (ìµëª… í•¨ìˆ˜)\n",
      "square = lambda x: x * x\n",
      "print(square(4))     # 16\n",
      "```\n",
      "\n",
      "### 4.5 í´ë˜ìŠ¤ì™€ ê°ì²´ì§€í–¥\n",
      "\n",
      "```python\n",
      "class Animal:\n",
      "    def __init__(self, name):\n",
      "        self.name = name\n",
      "\n",
      "    def speak(self):\n",
      "        raise NotImplementedError(\"subclass must implement\")\n",
      "\n",
      "class Dog(Animal):\n",
      "    def speak(self):\n",
      "        return \"ë©ë©!\"\n",
      "\n",
      "class Cat(Animal):\n",
      "    def speak(self):\n",
      "        return \"ì•¼ì˜¹!\"\n",
      "\n",
      "dog = Dog(\"ë°”ë‘‘ì´\")\n",
      "cat = Cat(\"ëƒ¥ì´\")\n",
      "print(dog.speak())   # ë©ë©!\n",
      "print(cat.speak())   # ì•¼ì˜¹!\n",
      "```\n",
      "\n",
      "### 4.6 ëª¨ë“ˆÂ·íŒ¨í‚¤ì§€ ì‚¬ìš©\n",
      "\n",
      "```python\n",
      "# my_module.py íŒŒì¼ì— ì •ì˜ëœ í•¨ìˆ˜\n",
      "def greet(name):\n",
      "    return f\"Hello, {name}!\"\n",
      "\n",
      "# ë‹¤ë¥¸ íŒŒì¼ì—ì„œ import\n",
      "import my_module\n",
      "print(my_module.greet(\"World\"))\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "## 5. íŒŒì´ì¬ ê°œë°œ í™˜ê²½ ì„¤ì •\n",
      "\n",
      "| ë‹¨ê³„ | ë‚´ìš© | ë„êµ¬/ì„¤ëª… |\n",
      "|------|------|-----------|\n",
      "| **1. íŒŒì´ì¬ ì„¤ì¹˜** | ê³µì‹ ì‚¬ì´íŠ¸(https://python.org)ì—ì„œ ìµœì‹  ë²„ì „ ë‹¤ìš´ë¡œë“œ ë° ì„¤ì¹˜. WindowsëŠ” `python.exe`ì— â€œAdd Python to PATHâ€ ì˜µì…˜ ì„ íƒ ê¶Œì¥. | CPython (ê°€ì¥ ë„ë¦¬ ì‚¬ìš©) |\n",
      "| **2. ê°€ìƒ í™˜ê²½(Virtual Environment)** | í”„ë¡œì íŠ¸ë§ˆë‹¤ ë…ë¦½ëœ íŒ¨í‚¤ì§€ ê´€ë¦¬. `venv` í˜¹ì€ `conda` ì‚¬ìš©. | `python -m venv venv` â†’ `source venv/bin/activate` |\n",
      "| **3. íŒ¨í‚¤ì§€ ê´€ë¦¬** | PyPIì—ì„œ íŒ¨í‚¤ì§€ ì„¤ì¹˜Â·ì—…ë°ì´íŠ¸. | `pip install numpy pandas` |\n",
      "| **4. IDE/ì—ë””í„°** | ì½”ë“œ ìë™ì™„ì„±Â·ë””ë²„ê¹…Â·ê°€ìƒ í™˜ê²½ ì—°ë™ ì§€ì›. | VS Code, PyCharm, Jupyter Notebook/Lab, Sublime Text ë“± |\n",
      "| **5. ì½”ë“œ í¬ë§·íŒ…Â·í’ˆì§ˆ** | PEP 8 ìŠ¤íƒ€ì¼ ê°€ì´ë“œ ìë™ ì ìš©, ì •ì  ë¶„ì„. | `black`, `flake8`, `mypy` |\n",
      "| **6. í…ŒìŠ¤íŠ¸** | ë‹¨ìœ„Â·í†µí•© í…ŒìŠ¤íŠ¸ ìë™í™”. | `unittest`, `pytest` |\n",
      "| **7. CI/CD** | GitHub Actions, GitLab CI ë“±ìœ¼ë¡œ ìë™ ë°°í¬Â·í…ŒìŠ¤íŠ¸ íŒŒì´í”„ë¼ì¸ êµ¬ì¶•. | `.github/workflows/python-app.yml` ë“± |\n",
      "\n",
      "---\n",
      "\n",
      "## 6. íŒŒì´ì¬ ì„±ëŠ¥ ìµœì í™” íŒ\n",
      "\n",
      "1. **í”„ë¡œíŒŒì¼ë§** â€“ `cProfile`, `line_profiler` ë¡œ ë³‘ëª© ì§€ì  íŒŒì•…  \n",
      "2. **ë‚´ì¥ í•¨ìˆ˜Â·í‘œí˜„ì‹ í™œìš©** â€“ `sum()`, `map()`, ë¦¬ìŠ¤íŠ¸ ì»´í”„ë¦¬í—¨ì…˜ ë“±ì€ C ë ˆë²¨ êµ¬í˜„ì´ë¼ ë¹ ë¦„  \n",
      "3. **NumPyÂ·Pandas** â€“ ë²¡í„°í™” ì—°ì‚°ì„ í†µí•´ íŒŒì´ì¬ ë£¨í”„ ëŒ€ì‹  C/Fortran ê¸°ë°˜ ì—°ì‚° ì‚¬ìš©  \n",
      "4. **ë©€í‹°ìŠ¤ë ˆë“œ vs ë©€í‹°í”„ë¡œì„¸ìŠ¤** â€“ GIL(Global Interpreter Lock) ë•Œë¬¸ì— CPU ë°”ìš´ë“œ ì‘ì—…ì€ `multiprocessing` í˜¹ì€ `concurrent.futures.ProcessPoolExecutor` ì‚¬ìš©  \n",
      "5. **CythonÂ·Numba** â€“ íŒŒì´ì¬ ì½”ë“œë¥¼ JIT ì»´íŒŒì¼í•˜ê±°ë‚˜ C í™•ì¥ ëª¨ë“ˆë¡œ ë³€í™˜  \n",
      "6. **ë¹„ë™ê¸° I/O** â€“ `asyncio`, `aiohttp` ë¡œ ë„¤íŠ¸ì›Œí¬Â·íŒŒì¼ I/O ë³‘ë ¬ ì²˜ë¦¬  \n",
      "\n",
      "---\n",
      "\n",
      "## 7. íŒŒì´ì¬ ì»¤ë®¤ë‹ˆí‹°ì™€ í•™ìŠµ ìë£Œ\n",
      "\n",
      "| ì¢…ë¥˜ | ì¶”ì²œ ë¦¬ì†ŒìŠ¤ |\n",
      "|------|-------------|\n",
      "| **ê³µì‹ ë¬¸ì„œ** | https://docs.python.org/3/ |\n",
      "| **ì˜¨ë¼ì¸ íŠœí† ë¦¬ì–¼** | Real Python, Corey Schafer (YouTube), freeCodeCamp |\n",
      "| **ì±…** | *â€œì í”„ íˆ¬ íŒŒì´ì¬â€* (ê¹€ì™¼ì†), *â€œFluent Pythonâ€* (Luciano Ramalho), *â€œPython Crash Courseâ€* |\n",
      "| **Q&A** | Stack Overflow, Reddit r/learnpython |\n",
      "| **ì˜¤í”„ë¼ì¸ ëª¨ì„** | PyCon (ì „ ì„¸ê³„), ê° ì§€ì—­ PyLadies, Django Girls |\n",
      "| **íŒ¨í‚¤ì§€ ë ˆì§€ìŠ¤íŠ¸ë¦¬** | PyPI (https://pypi.org/) |\n",
      "\n",
      "---\n",
      "\n",
      "## 8. ê°„ë‹¨í•œ í”„ë¡œì íŠ¸ ì•„ì´ë””ì–´ (ì‹œì‘ìš©)\n",
      "\n",
      "| ë¶„ì•¼ | ì•„ì´ë””ì–´ | í•µì‹¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ |\n",
      "|------|----------|-----------------|\n",
      "| **ì›¹** | ê°œì¸ ë¸”ë¡œê·¸ API ë§Œë“¤ê¸° | FastAPI, Uvicorn, SQLite |\n",
      "| **ë°ì´í„°** | CSV íŒŒì¼ì„ ì½ì–´ í†µê³„ ìš”ì•½ ë³´ê³ ì„œ ìƒì„± | pandas, matplotlib |\n",
      "| **ìë™í™”** | ì´ë©”ì¼ ìë™ ë°œì†¡ ìŠ¤í¬ë¦½íŠ¸ (ì¼ì¼ ë³´ê³ ) | smtplib, email, schedule |\n",
      "| **ë¨¸ì‹ ëŸ¬ë‹** | ì†ê¸€ì”¨ ìˆ«ì ì¸ì‹ (MNIST) | TensorFlow/Keras ë˜ëŠ” PyTorch |\n",
      "| **ê²Œì„** | ê°„ë‹¨í•œ ìŠ¤ë„¤ì´í¬ ê²Œì„ | pygame |\n",
      "| **IoT** | ë¼ì¦ˆë² ë¦¬íŒŒì´ ì˜¨ë„ ì„¼ì„œ ë°ì´í„° ë¡œê¹… | MicroPython, MQTT, InfluxDB |\n",
      "\n",
      "---\n",
      "\n",
      "## 9. ë§ˆë¬´ë¦¬ ì •ë¦¬\n",
      "\n",
      "- **íŒŒì´ì¬ì€** ë°°ìš°ê¸° ì‰¬ìš°ë©´ì„œë„ **í”„ë¡œë•ì…˜ ìˆ˜ì¤€**ì˜ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ë§Œë“¤ ìˆ˜ ìˆëŠ” ê°•ë ¥í•œ ì–¸ì–´ì…ë‹ˆë‹¤.  \n",
      "- **ê°€ë…ì„±**ê³¼ **í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬**ê°€ í’ë¶€í•´ ë¹ ë¥¸ í”„ë¡œí† íƒ€ì´í•‘ì´ ê°€ëŠ¥í•˜ê³ , **ì„œë“œíŒŒí‹° íŒ¨í‚¤ì§€**ê°€ ë°©ëŒ€í•´ ê±°ì˜ ëª¨ë“  ë¶„ì•¼ì— ì ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  \n",
      "- **Python 3**ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ìµœì‹  ë¬¸ë²•ê³¼ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í™œìš©í•˜ê³ , **ê°€ìƒ í™˜ê²½**Â·**íŒ¨í‚¤ì§€ ê´€ë¦¬**Â·**í…ŒìŠ¤íŠ¸**Â·**CI/CD**ë¥¼ ì ì ˆíˆ ë„ì…í•˜ë©´ ì•ˆì •ì ì¸ ê°œë°œ íë¦„ì„ êµ¬ì¶•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  \n",
      "\n",
      "ê¶ê¸ˆí•œ ì ì´ ìˆê±°ë‚˜ íŠ¹ì • ë¶„ì•¼(ì˜ˆ: ì›¹, ë°ì´í„° ê³¼í•™, ìë™í™” ë“±)ì— ëŒ€í•œ ì‹¬í™” ì„¤ëª…ì´ í•„ìš”í•˜ë©´ ì–¸ì œë“  ì•Œë ¤ ì£¼ì„¸ìš”! ğŸš€\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    response = llm.invoke(prompt_text)\n",
    "    print(type(response))\n",
    "    print(\"ì‘ë‹µ:\", response.content)\n",
    "except Exception as e:\n",
    "    print(f\"ì˜¤ë¥˜ ë°œìƒ: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n",
      "first=ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='ë‹¹ì‹ ì€ ê°œë°œìì…ë‹ˆë‹¤.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})]) middle=[ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x1550bd5b0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x1550bf230>, root_client=<openai.OpenAI object at 0x1550bcb00>, root_async_client=<openai.AsyncOpenAI object at 0x1550bf360>, model_name='openai/gpt-oss-120b', temperature=0.7, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://api.groq.com/openai/v1')] last=StrOutputParser()\n"
     ]
    }
   ],
   "source": [
    "chain = prompt | llm | output_parser\n",
    "print(type(chain))\n",
    "print(chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = chain.invoke({\"input\":\"ì§€êµ¬ì˜ ìì „ì£¼ê¸°ëŠ” ì–¼ë§ˆì¸ê°€ìš”?\"})\n",
    "response = chain.invoke({\"input\":\"LangChainì´ë€ ë¬´ì—‡ì¸ê°€ìš”?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "## LangChainì´ë€?\n",
      "\n",
      "**LangChain**ì€ **ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)**ì„ **ì• í”Œë¦¬ì¼€ì´ì…˜ ìˆ˜ì¤€**ìœ¼ë¡œ í™œìš©í•  ìˆ˜ ìˆê²Œ ë„ì™€ì£¼ëŠ” **í”„ë ˆì„ì›Œí¬**ì…ë‹ˆë‹¤. LLMì„ ë‹¨ìˆœíˆ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ë„êµ¬ë¡œ ì“°ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, **ë‹¤ì–‘í•œ ì™¸ë¶€ ë°ì´í„°Â·ë„êµ¬Â·ì›Œí¬í”Œë¡œì™€ ì—°ê²°**í•˜ì—¬ ë³µì¡í•œ ì—…ë¬´ íë¦„ì„ êµ¬í˜„í•  ìˆ˜ ìˆë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.  \n",
      "\n",
      "> â€œLLMì„ **í”„ë¡¬í”„íŠ¸**ë§Œìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, **ì²´ì¸(Chain)** í˜•íƒœë¡œ ì—¬ëŸ¬ ë‹¨ê³„ì™€ ì»´í¬ë„ŒíŠ¸ë¥¼ ì¡°í•©í•´ **ì—”ë“œâ€‘íˆ¬â€‘ì—”ë“œ** ì†”ë£¨ì…˜ì„ ë§Œë“ ë‹¤â€ëŠ” ê²ƒì´ LangChainì˜ í•µì‹¬ ì•„ì´ë””ì–´ì…ë‹ˆë‹¤.\n",
      "\n",
      "---\n",
      "\n",
      "## ì£¼ìš” íŠ¹ì§•\n",
      "\n",
      "| êµ¬ë¶„ | ì„¤ëª… |\n",
      "|------|------|\n",
      "| **ì»´í¬ë„ŒíŠ¸ ê¸°ë°˜ ì„¤ê³„** | `LLM`, `PromptTemplate`, `Memory`, `Retriever`, `Tool`, `Agent` ë“± ì¬ì‚¬ìš© ê°€ëŠ¥í•œ ë¸”ë¡ì„ ì œê³µ. |\n",
      "| **ì²´ì¸(Chain)** | ì—¬ëŸ¬ ì»´í¬ë„ŒíŠ¸ë¥¼ ìˆœì°¨Â·ì¡°ê±´ë¶€Â·ë°˜ë³µì ìœ¼ë¡œ ì—°ê²°í•´ ë³µì¡í•œ ë¡œì§ì„ êµ¬í˜„. |\n",
      "| **ì—ì´ì „íŠ¸(Agent)** | LLMì´ **ìì²´ì ìœ¼ë¡œ** ì–´ë–¤ ë„êµ¬ë¥¼ ì–¸ì œ ì‚¬ìš©í• ì§€ íŒë‹¨í•˜ë„ë¡ í”„ë ˆì„ì›Œí¬ê°€ ì§€ì›. (ì˜ˆ: ê²€ìƒ‰, ê³„ì‚°, ë°ì´í„°ë² ì´ìŠ¤ ì¡°íšŒ) |\n",
      "| **ë©”ëª¨ë¦¬(Memory)** | ëŒ€í™”í˜• ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ **ì»¨í…ìŠ¤íŠ¸**ë¥¼ ìœ ì§€Â·ê´€ë¦¬ (ì˜ˆ: ëŒ€í™” íˆìŠ¤í† ë¦¬, ìš”ì•½ ë“±). |\n",
      "| **ë¦¬íŠ¸ë¦¬ë²„(Retriever)Â·ë²¡í„° ìŠ¤í† ì–´** | í…ìŠ¤íŠ¸ ì„ë² ë”©ì„ ì´ìš©í•´ **ì§€ì‹ ê¸°ë°˜**ì„ êµ¬ì¶•í•˜ê³ , LLMì´ í•„ìš”í•  ë•Œ ê´€ë ¨ ì •ë³´ë¥¼ ê²€ìƒ‰. |\n",
      "| **ë©€í‹°ëª¨ë‹¬Â·í”ŒëŸ¬ê·¸ì¸** | ì´ë¯¸ì§€, ì½”ë“œ, CSV ë“± ë‹¤ì–‘í•œ ì…ë ¥ í˜•ì‹ê³¼ ì™¸ë¶€ API(ì˜ˆ: OpenAI, Anthropic, Cohere ë“±) ì—°ë™ ê°€ëŠ¥. |\n",
      "| **ë°°í¬ ì¹œí™”ì ** | LangServe, LangGraph, LangFuse ë“±ìœ¼ë¡œ **API ì„œë²„**, **ì›Œí¬í”Œë¡œ ê·¸ë˜í”„**, **íŒŒì´í”„ë¼ì¸**ì„ ì‰½ê²Œ ë°°í¬. |\n",
      "| **ì˜¤í”ˆì†ŒìŠ¤ & ì»¤ë®¤ë‹ˆí‹°** | GitHub(> 150k ìŠ¤íƒ€)ì™€ í™œë°œí•œ ì»¤ë®¤ë‹ˆí‹°ê°€ ì§€ì†ì ìœ¼ë¡œ ìƒˆë¡œìš´ ëª¨ë“ˆÂ·í…œí”Œë¦¿ì„ ì¶”ê°€. |\n",
      "\n",
      "---\n",
      "\n",
      "## í•µì‹¬ ì»´í¬ë„ŒíŠ¸\n",
      "\n",
      "1. **LLM**  \n",
      "   - `OpenAI`, `Anthropic`, `Cohere`, `AzureOpenAI`, `HuggingFace` ë“± ë‹¤ì–‘í•œ ëª¨ë¸ ë˜í¼.  \n",
      "   - `temperature`, `max_tokens` ë“± íŒŒë¼ë¯¸í„°ë¥¼ ì§ì ‘ ì œì–´.\n",
      "\n",
      "2. **PromptTemplate**  \n",
      "   - ë³€ìˆ˜(`{question}`, `{context}` ë“±)ë¥¼ í¬í•¨í•œ í”„ë¡¬í”„íŠ¸ë¥¼ ì¬ì‚¬ìš© ê°€ëŠ¥í•œ í˜•íƒœë¡œ ì •ì˜.  \n",
      "   - `ChatPromptTemplate`, `FewShotPromptTemplate` ë“± íŠ¹í™”ëœ í…œí”Œë¦¿ ì œê³µ.\n",
      "\n",
      "3. **Chain**  \n",
      "   - **SequentialChain**: ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰.  \n",
      "   - **RouterChain**: ì…ë ¥ì— ë”°ë¼ ë‹¤ë¥¸ ì„œë¸Œ ì²´ì¸ìœ¼ë¡œ ë¼ìš°íŒ….  \n",
      "   - **MapReduceChain**: ëŒ€ìš©ëŸ‰ í…ìŠ¤íŠ¸ë¥¼ ë¶„í• Â·ìš”ì•½Â·í†µí•©.\n",
      "\n",
      "4. **Memory**  \n",
      "   - `ConversationBufferMemory`, `ConversationSummaryMemory`, `VectorStoreRetrieverMemory` ë“±.  \n",
      "   - ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ ìë™ìœ¼ë¡œ í”„ë¡¬í”„íŠ¸ì— ì‚½ì….\n",
      "\n",
      "5. **Retriever / VectorStore**  \n",
      "   - `FAISS`, `Pinecone`, `Weaviate`, `Chroma` ë“± ë²¡í„° DBì™€ ì—°ë™í•´ **RAG(Retrievalâ€‘Augmented Generation)** êµ¬í˜„.\n",
      "\n",
      "6. **Tool & Agent**  \n",
      "   - `Tool`ì€ `name`, `description`, `func` ë¡œ ì •ì˜ëœ ì™¸ë¶€ í•¨ìˆ˜(ì˜ˆ: ê²€ìƒ‰, ê³„ì‚°, API í˜¸ì¶œ).  \n",
      "   - `Agent`ëŠ” LLMì´ `Tool`ì„ í˜¸ì¶œí•  ì‹œì ì„ ìŠ¤ìŠ¤ë¡œ íŒë‹¨. ëŒ€í‘œì ì¸ ì—ì´ì „íŠ¸: `ZeroShotAgent`, `ConversationalReactAgent`.\n",
      "\n",
      "7. **LangServe / LangGraph**  \n",
      "   - **LangServe**: ì²´ì¸ì„ HTTP APIë¡œ ì‰½ê²Œ ë°°í¬.  \n",
      "   - **LangGraph**: ìƒíƒœ ë¨¸ì‹  í˜•íƒœë¡œ ë³µì¡í•œ ì›Œí¬í”Œë¡œ(ì¡°ê±´Â·ë°˜ë³µÂ·ë¹„ë™ê¸°)ë¥¼ ì‹œê°ì ìœ¼ë¡œ ì •ì˜.\n",
      "\n",
      "---\n",
      "\n",
      "## ì¼ë°˜ì ì¸ ì‚¬ìš© íë¦„ (ì˜ˆì‹œ)\n",
      "\n",
      "```python\n",
      "# 1ï¸âƒ£ í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
      "# pip install langchain openai faiss-cpu\n",
      "\n",
      "from langchain.llms import OpenAI\n",
      "from langchain.prompts import PromptTemplate\n",
      "from langchain.chains import RetrievalQA\n",
      "from langchain.vectorstores import FAISS\n",
      "from langchain.embeddings import OpenAIEmbeddings\n",
      "from langchain.document_loaders import TextLoader\n",
      "\n",
      "# 2ï¸âƒ£ ë¬¸ì„œ ë¡œë“œ â†’ ì„ë² ë”© â†’ ë²¡í„°ìŠ¤í† ì–´ êµ¬ì¶•\n",
      "loader = TextLoader(\"knowledge_base.txt\")\n",
      "docs = loader.load_and_split()\n",
      "embeddings = OpenAIEmbeddings()\n",
      "vectorstore = FAISS.from_documents(docs, embeddings)\n",
      "\n",
      "# 3ï¸âƒ£ Retriever ì •ì˜\n",
      "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 4})\n",
      "\n",
      "# 4ï¸âƒ£ LLM ë° í”„ë¡¬í”„íŠ¸ ì •ì˜\n",
      "llm = OpenAI(model=\"gpt-4o-mini\", temperature=0.0)\n",
      "prompt = PromptTemplate(\n",
      "    template=\"ë‹¤ìŒ ë¬¸ì„œë“¤ì„ ì°¸ê³ í•´ì„œ ì§ˆë¬¸ì— ë‹µë³€í•´ ì£¼ì„¸ìš”:\\n{context}\\n\\nì§ˆë¬¸: {question}\",\n",
      "    input_variables=[\"context\", \"question\"]\n",
      ")\n",
      "\n",
      "# 5ï¸âƒ£ RetrievalQA ì²´ì¸ ìƒì„±\n",
      "qa_chain = RetrievalQA.from_chain_type(\n",
      "    llm=llm,\n",
      "    chain_type=\"stuff\",          # \"map_reduce\", \"refine\" ë“±ë„ ê°€ëŠ¥\n",
      "    retriever=retriever,\n",
      "    return_source_documents=True,\n",
      "    combine_prompt=prompt\n",
      ")\n",
      "\n",
      "# 6ï¸âƒ£ ì§ˆë¬¸ ì‹¤í–‰\n",
      "result = qa_chain({\"query\": \"ì¸ê³µì§€ëŠ¥ ìœ¤ë¦¬ ì›ì¹™ì€ ë¬´ì—‡ì¸ê°€ìš”?\"})\n",
      "print(result[\"answer\"])\n",
      "print(\"ì¶œì²˜:\", [doc.metadata[\"source\"] for doc in result[\"source_documents\"]])\n",
      "```\n",
      "\n",
      "ìœ„ ì˜ˆì‹œëŠ” **RAG**(Retrievalâ€‘Augmented Generation) í˜•íƒœì˜ ê°€ì¥ ê¸°ë³¸ì ì¸ íë¦„ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  \n",
      "- ë¬¸ì„œë¥¼ ì„ë² ë”© â†’ ë²¡í„°ìŠ¤í† ì–´ì— ì €ì¥  \n",
      "- ì§ˆë¬¸ì´ ë“¤ì–´ì˜¤ë©´ ê´€ë ¨ ë¬¸ì„œ 4ê°œë¥¼ ê²€ìƒ‰ â†’ LLMì—ê²Œ í”„ë¡¬í”„íŠ¸ì™€ í•¨ê»˜ ì „ë‹¬ â†’ ë‹µë³€ ìƒì„±  \n",
      "\n",
      "---\n",
      "\n",
      "## ì‹¤ì œ ì ìš© ì‚¬ë¡€\n",
      "\n",
      "| ë¶„ì•¼ | í™œìš© ì˜ˆì‹œ |\n",
      "|------|-----------|\n",
      "| **ê³ ê°ì§€ì› ì±—ë´‡** | ê³ ê° ë¬¸ì˜ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ê²€ìƒ‰Â·ë‹µë³€. `ConversationBufferMemory` ë¡œ ëŒ€í™” íë¦„ ìœ ì§€. |\n",
      "| **ì½”ë“œ ìë™ìƒì„±** | `LLM` + `Tool`(GitHub API) ë¡œ ì½”ë“œ ìŠ¤ë‹ˆí«ì„ ê²€ìƒ‰Â·ìƒì„±, PR ìë™ ìƒì„±. |\n",
      "| **ë°ì´í„° ë¶„ì„** | `PythonREPLTool` ê³¼ ê²°í•©í•´ ìì—°ì–´ë¡œ ë¶„ì„ ì§ˆë¬¸ â†’ Python ì½”ë“œë¥¼ ì‹¤í–‰í•˜ê³  ê²°ê³¼ ë°˜í™˜. |\n",
      "| **ë²•ë¥ Â·ì˜ë£Œ ì§€ì‹ë² ì´ìŠ¤** | ë¯¼ê°í•œ ë¬¸ì„œë“¤ì„ ë²¡í„°ìŠ¤í† ì–´ì— ë³´ê´€í•˜ê³ , RAG ë¡œ ì •í™•í•œ ê·¼ê±°ì™€ í•¨ê»˜ ë‹µë³€ ì œê³µ. |\n",
      "| **ë©€í‹°ëª¨ë‹¬ ì–´ì‹œìŠ¤í„´íŠ¸** | ì´ë¯¸ì§€ ìº¡ì…˜ ìƒì„± + í…ìŠ¤íŠ¸ ìš”ì•½ì„ í•˜ë‚˜ì˜ ì²´ì¸ìœ¼ë¡œ ì—°ê²°í•´ ë³´ê³ ì„œ ìë™ì‘ì„±. |\n",
      "| **ì›Œí¬í”Œë¡œ ìë™í™”** | `LangGraph` ë¡œ â€œì´ë©”ì¼ â†’ ì¼ì • í™•ì¸ â†’ íšŒì˜ì‹¤ ì˜ˆì•½â€ ê°™ì€ ë³µí•© í”„ë¡œì„¸ìŠ¤ë¥¼ ìƒíƒœ ë¨¸ì‹ ìœ¼ë¡œ êµ¬í˜„. |\n",
      "\n",
      "---\n",
      "\n",
      "## ì‹œì‘í•˜ê¸° ìœ„í•œ íŒ\n",
      "\n",
      "1. **í”„ë¡œì íŠ¸ ëª©í‘œë¥¼ ëª…í™•íˆ**  \n",
      "   - ë‹¨ìˆœ í…ìŠ¤íŠ¸ ìƒì„± â†’ `LLM`ë§Œ ì‚¬ìš©.  \n",
      "   - ì™¸ë¶€ ì§€ì‹Â·ë„êµ¬ ì—°ë™ â†’ `Retriever`, `Tool`, `Agent` ë„ì….\n",
      "\n",
      "2. **í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ ë¨¼ì € ì„¤ê³„**  \n",
      "   - ë³€ìˆ˜ì™€ ì„¤ëª…ì„ ëª…í™•íˆ ì ì–´ë‘ë©´ ì²´ì¸ ì¬ì‚¬ìš©ì´ ì‰¬ì›Œì§‘ë‹ˆë‹¤.\n",
      "\n",
      "3. **ë©”ëª¨ë¦¬ì™€ ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬**  \n",
      "   - ëŒ€í™”í˜• ì•±ì´ë¼ë©´ `ConversationBufferMemory` ë¡œ íˆìŠ¤í† ë¦¬ë¥¼ ìë™ ì‚½ì….  \n",
      "   - í† í° ì œí•œì´ ìˆì„ ê²½ìš° `ConversationSummaryMemory` ë¡œ ìš”ì•½ì„ ì ìš©.\n",
      "\n",
      "4. **ë²¡í„°ìŠ¤í† ì–´ ì„ íƒ**  \n",
      "   - ë¡œì»¬ í…ŒìŠ¤íŠ¸ â†’ `FAISS` í˜¹ì€ `Chroma`.  \n",
      "   - í”„ë¡œë•ì…˜ â†’ `Pinecone`, `Weaviate`, `Milvus` ë“± í´ë¼ìš°ë“œ ê¸°ë°˜ì„ ê¶Œì¥.\n",
      "\n",
      "5. **ì—ì´ì „íŠ¸ ì‚¬ìš© ì‹œ**  \n",
      "   - ë„êµ¬ë¥¼ **ëª…í™•íˆ ì •ì˜**í•˜ê³ , `description`ì— ì‚¬ìš© ëª©ì ì„ ìƒì„¸íˆ ì ì–´ì•¼ LLMì´ ì˜¬ë°”ë¥´ê²Œ ì„ íƒí•©ë‹ˆë‹¤.\n",
      "\n",
      "6. **ë°°í¬**  \n",
      "   - `LangServe` ë¡œ FastAPI ê¸°ë°˜ ì—”ë“œí¬ì¸íŠ¸ë¥¼ í•œ ì¤„ ì½”ë“œë¡œ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.  \n",
      "   - `Dockerfile`ì— `langserve`ì™€ `uvicorn`ì„ í¬í•¨í•´ ì»¨í…Œì´ë„ˆí™”í•˜ë©´ CI/CD íŒŒì´í”„ë¼ì¸ì— ì‰½ê²Œ ì—°ê²°.\n",
      "\n",
      "---\n",
      "\n",
      "## ê°„ë‹¨í•œ LangServe ì˜ˆì‹œ\n",
      "\n",
      "```python\n",
      "# app.py\n",
      "from fastapi import FastAPI\n",
      "from langserve import add_routes\n",
      "from langchain.chains import LLMChain\n",
      "from langchain.prompts import PromptTemplate\n",
      "from langchain.llms import OpenAI\n",
      "\n",
      "app = FastAPI()\n",
      "\n",
      "prompt = PromptTemplate.from_template(\"ë‹¤ìŒ ë¬¸ì¥ì„ í•œêµ­ì–´ë¡œ ë²ˆì—­í•´ ì£¼ì„¸ìš”: {text}\")\n",
      "chain = LLMChain(llm=OpenAI(model=\"gpt-4o-mini\"), prompt=prompt)\n",
      "\n",
      "add_routes(app, chain, path=\"/translate\")\n",
      "```\n",
      "\n",
      "```bash\n",
      "# ì‹¤í–‰\n",
      "uvicorn app:app --host 0.0.0.0 --port 8000\n",
      "# ì´ì œ POST /translate {\"text\":\"Hello, world!\"} ë¡œ ë²ˆì—­ API ì‚¬ìš© ê°€ëŠ¥\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "## ë§ˆë¬´ë¦¬\n",
      "\n",
      "- **LangChain**ì€ LLMì„ **í”„ë¡¬í”„íŠ¸ ìˆ˜ì¤€**ì´ ì•„ë‹ˆë¼ **ì‹œìŠ¤í…œ ìˆ˜ì¤€**ì—ì„œ í™œìš©í•˜ë„ë¡ ì„¤ê³„ëœ **ëª¨ë“ˆí˜• í”„ë ˆì„ì›Œí¬**ì…ë‹ˆë‹¤.  \n",
      "- `Chain`, `Agent`, `Memory`, `Retriever` ë“± í•µì‹¬ ì»´í¬ë„ŒíŠ¸ë¥¼ ì¡°í•©í•˜ë©´ **ê²€ìƒ‰Â·ê³„ì‚°Â·ë°ì´í„°ë² ì´ìŠ¤Â·ë©€í‹°ëª¨ë‹¬** ë“± ë‹¤ì–‘í•œ ê¸°ëŠ¥ì„ ê°–ì¶˜ **ì§€ëŠ¥í˜• ì–´í”Œë¦¬ì¼€ì´ì…˜**ì„ ë¹ ë¥´ê²Œ êµ¬ì¶•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  \n",
      "- ì˜¤í”ˆì†ŒìŠ¤ì´ë©° í™œë°œí•œ ì»¤ë®¤ë‹ˆí‹°ê°€ ì§€ì†ì ìœ¼ë¡œ ìƒˆë¡œìš´ ë„êµ¬Â·í…œí”Œë¦¿ì„ ì œê³µí•˜ë¯€ë¡œ, í”„ë¡œì íŠ¸ ì´ˆê¸°ë¶€í„° ìµœì‹  ê¸°ëŠ¥ì„ ì ìš©í•˜ê¸° ìš©ì´í•©ë‹ˆë‹¤.\n",
      "\n",
      "ê¶ê¸ˆí•œ ì ì´ë‚˜ êµ¬ì²´ì ì¸ êµ¬í˜„ ì˜ˆì‹œê°€ í•„ìš”í•˜ë©´ ì–¸ì œë“  ì•Œë ¤ ì£¼ì„¸ìš”! ğŸš€\n"
     ]
    }
   ],
   "source": [
    "print(type(response))\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mylangchain-app-75wTJiYg-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
