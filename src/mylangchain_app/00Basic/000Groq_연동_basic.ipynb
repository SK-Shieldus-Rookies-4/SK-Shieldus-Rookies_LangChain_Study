{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello LangChain\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello LangChain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gsk_oohxJ\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI \n",
    "\n",
    "# load_dotenv(dotenv_path='.env')\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:9])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.prompts.chat.ChatPromptTemplate'>\n",
      "input_variables=['input'] input_types={} partial_variables={} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='당신은 개발자입니다.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "# prompt + llm + output \n",
    "\n",
    "# prompt\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [ (\"system\", \"당신은 개발자입니다.\") , \n",
    "     (\"user\", \"{input}\") ]\n",
    ")\n",
    "print(type(prompt))\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "System: 당신은 개발자입니다.\n",
      "Human: 파이썬은 무엇인가요? 자세하게 설명해주세요\n"
     ]
    }
   ],
   "source": [
    "prompt_text = prompt.format(input=\"파이썬은 무엇인가요? 자세하게 설명해주세요\")\n",
    "print(type(prompt_text))\n",
    "print(prompt_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_openai.chat_models.base.ChatOpenAI'>\n",
      "client=<openai.resources.chat.completions.completions.Completions object at 0x1550bd5b0> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x1550bf230> root_client=<openai.OpenAI object at 0x1550bcb00> root_async_client=<openai.AsyncOpenAI object at 0x1550bf360> model_name='openai/gpt-oss-120b' temperature=0.7 model_kwargs={} openai_api_key=SecretStr('**********') openai_api_base='https://api.groq.com/openai/v1'\n"
     ]
    }
   ],
   "source": [
    "#llm = ChatOpenAI(api_key=OPENAI_API_KEY, model_name=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "# Groq API를 사용하는 ChatOpenAI 인스턴스 생성\n",
    "llm = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    #model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    # model=\"moonshotai/kimi-k2-instruct-0905\",\n",
    "    model=\"openai/gpt-oss-120b\",\n",
    "    temperature=0.7\n",
    ")\n",
    "print(type(llm))\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "응답: ## 파이썬(Python)이란?\n",
      "\n",
      "파이썬은 **고수준(high-level), 인터프리터형(interpreted), 동적 타이핑(dynamic typing)** 언어이며, **코드 가독성**과 **생산성**을 최우선으로 설계된 프로그래밍 언어입니다. 1991년 네덜란드의 프로그래머 **귀도 반 로썸(Guido van Rossum)**이 처음 발표했으며, 현재는 전 세계 개발자 커뮤니티와 기업에서 폭넓게 사용되고 있습니다.\n",
      "\n",
      "---\n",
      "\n",
      "## 1. 파이썬의 주요 특징\n",
      "\n",
      "| 특징 | 설명 |\n",
      "|------|------|\n",
      "| **가독성 높은 문법** | 들여쓰기(indent) 기반 블록 구조, 최소한의 구문(syntax)으로 복잡한 로직을 간결하게 표현 |\n",
      "| **동적 타이핑** | 변수 선언 시 타입을 명시하지 않아도 되며, 실행 시점에 타입이 결정 |\n",
      "| **인터프리터 언어** | 코드를 한 줄씩 바로 실행(컴파일 단계 없이) → 빠른 테스트와 프로토타이핑 가능 |\n",
      "| **광범위한 표준 라이브러리** | “배터리 포함(batteries‑included)” 철학에 따라 파일 I/O, 네트워킹, 웹, 데이터베이스, 암호화 등 다양한 기능을 기본 제공 |\n",
      "| **멀티패러다임 지원** | 절차적, 객체지향, 함수형 프로그래밍을 모두 지원 |\n",
      "| **플랫폼 독립성** | Windows, macOS, Linux, 그리고 모바일/임베디드 환경까지 다양한 OS에서 동일하게 실행 |\n",
      "| **확장성** | C/C++ 로 작성된 모듈(Cython, CPython)이나 Java 기반 모듈(Jython) 등으로 성능을 보강 가능 |\n",
      "| **풍부한 서드파티 생태계** | PyPI(Python Package Index) 에 30만 개가 넘는 패키지 제공 (예: NumPy, pandas, TensorFlow, Django 등) |\n",
      "\n",
      "---\n",
      "\n",
      "## 2. 파이썬의 역사\n",
      "\n",
      "| 연도 | 사건 |\n",
      "|------|------|\n",
      "| **1980년대 후반** | 귀도 반 로썸이 “ABC” 언어의 경험을 바탕으로 새로운 언어 설계 시작 |\n",
      "| **1991년** | 첫 번째 공개 버전 **Python 0.9.0** 발표 (예외 처리, 모듈 시스템 등 기본 기능 포함) |\n",
      "| **1994년** | **Python 1.0** 출시 – 모듈, 함수, 예외 처리 등 정식 기능 제공 |\n",
      "| **2000년** | **Python 2.0** 발표 – 리스트 컴프리헨션, 가비지 컬렉션, 유니코드 지원 등 |\n",
      "| **2008년** | **Python 3.0** 발표 – 언어 자체를 정리·정비 (문자열/바이트 구분, print 함수화 등) |\n",
      "| **2020년** | **Python 3.9** 출시 – 새로운 문법(`:=` 연산자 등)과 성능 개선 |\n",
      "| **2023년** | **Python 3.12** 출시 – 패턴 매칭 강화, 인터프리터 최적화 등 |\n",
      "| **현재** | 활발한 커뮤니티와 연간 2~3번의 주요 릴리즈가 진행 중 (2025년 현재 최신 버전은 3.13.x) |\n",
      "\n",
      "> **핵심 포인트**: Python 2와 3는 호환성이 낮아 Python 2는 2020년 공식 지원이 종료되었습니다. 새 프로젝트는 반드시 Python 3를 사용해야 합니다.\n",
      "\n",
      "---\n",
      "\n",
      "## 3. 파이썬이 널리 쓰이는 분야\n",
      "\n",
      "| 분야 | 활용 예시 |\n",
      "|------|-----------|\n",
      "| **웹 개발** | Django, Flask, FastAPI 등 프레임워크를 이용한 서버·API 구현 |\n",
      "| **데이터 과학·분석** | NumPy, pandas, Matplotlib, Seaborn 등을 통한 데이터 전처리·시각화 |\n",
      "| **머신러닝·딥러닝** | scikit-learn, TensorFlow, PyTorch, Keras 등으로 모델 구축·학습 |\n",
      "| **자동화·스크립트** | 시스템 관리, 파일 처리, 테스트 자동화, 웹 스크래핑(BeautifulSoup, Selenium) |\n",
      "| **과학·공학** | SciPy, SymPy, Jupyter Notebook을 이용한 시뮬레이션·연구 |\n",
      "| **게임 개발** | Pygame, Panda3D 등으로 간단한 2D/3D 게임 제작 |\n",
      "| **임베디드·IoT** | MicroPython, CircuitPython으로 마이크로컨트롤러 프로그래밍 |\n",
      "| **교육** | 문법이 직관적이라 프로그래밍 입문 교육에 최적 |\n",
      "\n",
      "---\n",
      "\n",
      "## 4. 파이썬 기본 문법 소개\n",
      "\n",
      "### 4.1 변수와 자료형\n",
      "\n",
      "```python\n",
      "# 정수, 실수, 문자열, 불리언\n",
      "a = 10          # int\n",
      "b = 3.14        # float\n",
      "name = \"Alice\" # str\n",
      "flag = True    # bool\n",
      "```\n",
      "\n",
      "### 4.2 컬렉션(시퀀스·매핑)\n",
      "\n",
      "```python\n",
      "# 리스트, 튜플, 딕셔너리, 집합\n",
      "numbers = [1, 2, 3, 4]          # list\n",
      "coords  = (10, 20)              # tuple (불변)\n",
      "person  = {\"name\": \"Bob\", \"age\": 30}  # dict\n",
      "unique  = {1, 2, 3}             # set\n",
      "```\n",
      "\n",
      "### 4.3 제어 흐름\n",
      "\n",
      "```python\n",
      "# if-elif-else\n",
      "if a > 0:\n",
      "    print(\"양수\")\n",
      "elif a == 0:\n",
      "    print(\"0\")\n",
      "else:\n",
      "    print(\"음수\")\n",
      "\n",
      "# for 루프 (리스트 순회)\n",
      "for num in numbers:\n",
      "    print(num * 2)\n",
      "\n",
      "# while 루프\n",
      "i = 0\n",
      "while i < 5:\n",
      "    print(i)\n",
      "    i += 1\n",
      "```\n",
      "\n",
      "### 4.4 함수 정의와 람다\n",
      "\n",
      "```python\n",
      "def add(x, y):\n",
      "    \"\"\"두 숫자의 합을 반환합니다.\"\"\"\n",
      "    return x + y\n",
      "\n",
      "# 호출\n",
      "result = add(3, 5)   # 8\n",
      "\n",
      "# 람다 함수 (익명 함수)\n",
      "square = lambda x: x * x\n",
      "print(square(4))     # 16\n",
      "```\n",
      "\n",
      "### 4.5 클래스와 객체지향\n",
      "\n",
      "```python\n",
      "class Animal:\n",
      "    def __init__(self, name):\n",
      "        self.name = name\n",
      "\n",
      "    def speak(self):\n",
      "        raise NotImplementedError(\"subclass must implement\")\n",
      "\n",
      "class Dog(Animal):\n",
      "    def speak(self):\n",
      "        return \"멍멍!\"\n",
      "\n",
      "class Cat(Animal):\n",
      "    def speak(self):\n",
      "        return \"야옹!\"\n",
      "\n",
      "dog = Dog(\"바둑이\")\n",
      "cat = Cat(\"냥이\")\n",
      "print(dog.speak())   # 멍멍!\n",
      "print(cat.speak())   # 야옹!\n",
      "```\n",
      "\n",
      "### 4.6 모듈·패키지 사용\n",
      "\n",
      "```python\n",
      "# my_module.py 파일에 정의된 함수\n",
      "def greet(name):\n",
      "    return f\"Hello, {name}!\"\n",
      "\n",
      "# 다른 파일에서 import\n",
      "import my_module\n",
      "print(my_module.greet(\"World\"))\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "## 5. 파이썬 개발 환경 설정\n",
      "\n",
      "| 단계 | 내용 | 도구/설명 |\n",
      "|------|------|-----------|\n",
      "| **1. 파이썬 설치** | 공식 사이트(https://python.org)에서 최신 버전 다운로드 및 설치. Windows는 `python.exe`에 “Add Python to PATH” 옵션 선택 권장. | CPython (가장 널리 사용) |\n",
      "| **2. 가상 환경(Virtual Environment)** | 프로젝트마다 독립된 패키지 관리. `venv` 혹은 `conda` 사용. | `python -m venv venv` → `source venv/bin/activate` |\n",
      "| **3. 패키지 관리** | PyPI에서 패키지 설치·업데이트. | `pip install numpy pandas` |\n",
      "| **4. IDE/에디터** | 코드 자동완성·디버깅·가상 환경 연동 지원. | VS Code, PyCharm, Jupyter Notebook/Lab, Sublime Text 등 |\n",
      "| **5. 코드 포맷팅·품질** | PEP 8 스타일 가이드 자동 적용, 정적 분석. | `black`, `flake8`, `mypy` |\n",
      "| **6. 테스트** | 단위·통합 테스트 자동화. | `unittest`, `pytest` |\n",
      "| **7. CI/CD** | GitHub Actions, GitLab CI 등으로 자동 배포·테스트 파이프라인 구축. | `.github/workflows/python-app.yml` 등 |\n",
      "\n",
      "---\n",
      "\n",
      "## 6. 파이썬 성능 최적화 팁\n",
      "\n",
      "1. **프로파일링** – `cProfile`, `line_profiler` 로 병목 지점 파악  \n",
      "2. **내장 함수·표현식 활용** – `sum()`, `map()`, 리스트 컴프리헨션 등은 C 레벨 구현이라 빠름  \n",
      "3. **NumPy·Pandas** – 벡터화 연산을 통해 파이썬 루프 대신 C/Fortran 기반 연산 사용  \n",
      "4. **멀티스레드 vs 멀티프로세스** – GIL(Global Interpreter Lock) 때문에 CPU 바운드 작업은 `multiprocessing` 혹은 `concurrent.futures.ProcessPoolExecutor` 사용  \n",
      "5. **Cython·Numba** – 파이썬 코드를 JIT 컴파일하거나 C 확장 모듈로 변환  \n",
      "6. **비동기 I/O** – `asyncio`, `aiohttp` 로 네트워크·파일 I/O 병렬 처리  \n",
      "\n",
      "---\n",
      "\n",
      "## 7. 파이썬 커뮤니티와 학습 자료\n",
      "\n",
      "| 종류 | 추천 리소스 |\n",
      "|------|-------------|\n",
      "| **공식 문서** | https://docs.python.org/3/ |\n",
      "| **온라인 튜토리얼** | Real Python, Corey Schafer (YouTube), freeCodeCamp |\n",
      "| **책** | *“점프 투 파이썬”* (김왼손), *“Fluent Python”* (Luciano Ramalho), *“Python Crash Course”* |\n",
      "| **Q&A** | Stack Overflow, Reddit r/learnpython |\n",
      "| **오프라인 모임** | PyCon (전 세계), 각 지역 PyLadies, Django Girls |\n",
      "| **패키지 레지스트리** | PyPI (https://pypi.org/) |\n",
      "\n",
      "---\n",
      "\n",
      "## 8. 간단한 프로젝트 아이디어 (시작용)\n",
      "\n",
      "| 분야 | 아이디어 | 핵심 라이브러리 |\n",
      "|------|----------|-----------------|\n",
      "| **웹** | 개인 블로그 API 만들기 | FastAPI, Uvicorn, SQLite |\n",
      "| **데이터** | CSV 파일을 읽어 통계 요약 보고서 생성 | pandas, matplotlib |\n",
      "| **자동화** | 이메일 자동 발송 스크립트 (일일 보고) | smtplib, email, schedule |\n",
      "| **머신러닝** | 손글씨 숫자 인식 (MNIST) | TensorFlow/Keras 또는 PyTorch |\n",
      "| **게임** | 간단한 스네이크 게임 | pygame |\n",
      "| **IoT** | 라즈베리파이 온도 센서 데이터 로깅 | MicroPython, MQTT, InfluxDB |\n",
      "\n",
      "---\n",
      "\n",
      "## 9. 마무리 정리\n",
      "\n",
      "- **파이썬은** 배우기 쉬우면서도 **프로덕션 수준**의 애플리케이션을 만들 수 있는 강력한 언어입니다.  \n",
      "- **가독성**과 **표준 라이브러리**가 풍부해 빠른 프로토타이핑이 가능하고, **서드파티 패키지**가 방대해 거의 모든 분야에 적용할 수 있습니다.  \n",
      "- **Python 3**를 기준으로 최신 문법과 라이브러리를 활용하고, **가상 환경**·**패키지 관리**·**테스트**·**CI/CD**를 적절히 도입하면 안정적인 개발 흐름을 구축할 수 있습니다.  \n",
      "\n",
      "궁금한 점이 있거나 특정 분야(예: 웹, 데이터 과학, 자동화 등)에 대한 심화 설명이 필요하면 언제든 알려 주세요! 🚀\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    response = llm.invoke(prompt_text)\n",
    "    print(type(response))\n",
    "    print(\"응답:\", response.content)\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n",
      "first=ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='당신은 개발자입니다.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})]) middle=[ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x1550bd5b0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x1550bf230>, root_client=<openai.OpenAI object at 0x1550bcb00>, root_async_client=<openai.AsyncOpenAI object at 0x1550bf360>, model_name='openai/gpt-oss-120b', temperature=0.7, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://api.groq.com/openai/v1')] last=StrOutputParser()\n"
     ]
    }
   ],
   "source": [
    "chain = prompt | llm | output_parser\n",
    "print(type(chain))\n",
    "print(chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = chain.invoke({\"input\":\"지구의 자전주기는 얼마인가요?\"})\n",
    "response = chain.invoke({\"input\":\"LangChain이란 무엇인가요?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "## LangChain이란?\n",
      "\n",
      "**LangChain**은 **대규모 언어 모델(LLM)**을 **애플리케이션 수준**으로 활용할 수 있게 도와주는 **프레임워크**입니다. LLM을 단순히 텍스트를 생성하는 도구로 쓰는 것이 아니라, **다양한 외부 데이터·도구·워크플로와 연결**하여 복잡한 업무 흐름을 구현할 수 있도록 설계되었습니다.  \n",
      "\n",
      "> “LLM을 **프롬프트**만으로 사용하는 것이 아니라, **체인(Chain)** 형태로 여러 단계와 컴포넌트를 조합해 **엔드‑투‑엔드** 솔루션을 만든다”는 것이 LangChain의 핵심 아이디어입니다.\n",
      "\n",
      "---\n",
      "\n",
      "## 주요 특징\n",
      "\n",
      "| 구분 | 설명 |\n",
      "|------|------|\n",
      "| **컴포넌트 기반 설계** | `LLM`, `PromptTemplate`, `Memory`, `Retriever`, `Tool`, `Agent` 등 재사용 가능한 블록을 제공. |\n",
      "| **체인(Chain)** | 여러 컴포넌트를 순차·조건부·반복적으로 연결해 복잡한 로직을 구현. |\n",
      "| **에이전트(Agent)** | LLM이 **자체적으로** 어떤 도구를 언제 사용할지 판단하도록 프레임워크가 지원. (예: 검색, 계산, 데이터베이스 조회) |\n",
      "| **메모리(Memory)** | 대화형 애플리케이션에서 **컨텍스트**를 유지·관리 (예: 대화 히스토리, 요약 등). |\n",
      "| **리트리버(Retriever)·벡터 스토어** | 텍스트 임베딩을 이용해 **지식 기반**을 구축하고, LLM이 필요할 때 관련 정보를 검색. |\n",
      "| **멀티모달·플러그인** | 이미지, 코드, CSV 등 다양한 입력 형식과 외부 API(예: OpenAI, Anthropic, Cohere 등) 연동 가능. |\n",
      "| **배포 친화적** | LangServe, LangGraph, LangFuse 등으로 **API 서버**, **워크플로 그래프**, **파이프라인**을 쉽게 배포. |\n",
      "| **오픈소스 & 커뮤니티** | GitHub(> 150k 스타)와 활발한 커뮤니티가 지속적으로 새로운 모듈·템플릿을 추가. |\n",
      "\n",
      "---\n",
      "\n",
      "## 핵심 컴포넌트\n",
      "\n",
      "1. **LLM**  \n",
      "   - `OpenAI`, `Anthropic`, `Cohere`, `AzureOpenAI`, `HuggingFace` 등 다양한 모델 래퍼.  \n",
      "   - `temperature`, `max_tokens` 등 파라미터를 직접 제어.\n",
      "\n",
      "2. **PromptTemplate**  \n",
      "   - 변수(`{question}`, `{context}` 등)를 포함한 프롬프트를 재사용 가능한 형태로 정의.  \n",
      "   - `ChatPromptTemplate`, `FewShotPromptTemplate` 등 특화된 템플릿 제공.\n",
      "\n",
      "3. **Chain**  \n",
      "   - **SequentialChain**: 순차적으로 실행.  \n",
      "   - **RouterChain**: 입력에 따라 다른 서브 체인으로 라우팅.  \n",
      "   - **MapReduceChain**: 대용량 텍스트를 분할·요약·통합.\n",
      "\n",
      "4. **Memory**  \n",
      "   - `ConversationBufferMemory`, `ConversationSummaryMemory`, `VectorStoreRetrieverMemory` 등.  \n",
      "   - 대화 히스토리를 자동으로 프롬프트에 삽입.\n",
      "\n",
      "5. **Retriever / VectorStore**  \n",
      "   - `FAISS`, `Pinecone`, `Weaviate`, `Chroma` 등 벡터 DB와 연동해 **RAG(Retrieval‑Augmented Generation)** 구현.\n",
      "\n",
      "6. **Tool & Agent**  \n",
      "   - `Tool`은 `name`, `description`, `func` 로 정의된 외부 함수(예: 검색, 계산, API 호출).  \n",
      "   - `Agent`는 LLM이 `Tool`을 호출할 시점을 스스로 판단. 대표적인 에이전트: `ZeroShotAgent`, `ConversationalReactAgent`.\n",
      "\n",
      "7. **LangServe / LangGraph**  \n",
      "   - **LangServe**: 체인을 HTTP API로 쉽게 배포.  \n",
      "   - **LangGraph**: 상태 머신 형태로 복잡한 워크플로(조건·반복·비동기)를 시각적으로 정의.\n",
      "\n",
      "---\n",
      "\n",
      "## 일반적인 사용 흐름 (예시)\n",
      "\n",
      "```python\n",
      "# 1️⃣ 필요한 라이브러리 설치\n",
      "# pip install langchain openai faiss-cpu\n",
      "\n",
      "from langchain.llms import OpenAI\n",
      "from langchain.prompts import PromptTemplate\n",
      "from langchain.chains import RetrievalQA\n",
      "from langchain.vectorstores import FAISS\n",
      "from langchain.embeddings import OpenAIEmbeddings\n",
      "from langchain.document_loaders import TextLoader\n",
      "\n",
      "# 2️⃣ 문서 로드 → 임베딩 → 벡터스토어 구축\n",
      "loader = TextLoader(\"knowledge_base.txt\")\n",
      "docs = loader.load_and_split()\n",
      "embeddings = OpenAIEmbeddings()\n",
      "vectorstore = FAISS.from_documents(docs, embeddings)\n",
      "\n",
      "# 3️⃣ Retriever 정의\n",
      "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 4})\n",
      "\n",
      "# 4️⃣ LLM 및 프롬프트 정의\n",
      "llm = OpenAI(model=\"gpt-4o-mini\", temperature=0.0)\n",
      "prompt = PromptTemplate(\n",
      "    template=\"다음 문서들을 참고해서 질문에 답변해 주세요:\\n{context}\\n\\n질문: {question}\",\n",
      "    input_variables=[\"context\", \"question\"]\n",
      ")\n",
      "\n",
      "# 5️⃣ RetrievalQA 체인 생성\n",
      "qa_chain = RetrievalQA.from_chain_type(\n",
      "    llm=llm,\n",
      "    chain_type=\"stuff\",          # \"map_reduce\", \"refine\" 등도 가능\n",
      "    retriever=retriever,\n",
      "    return_source_documents=True,\n",
      "    combine_prompt=prompt\n",
      ")\n",
      "\n",
      "# 6️⃣ 질문 실행\n",
      "result = qa_chain({\"query\": \"인공지능 윤리 원칙은 무엇인가요?\"})\n",
      "print(result[\"answer\"])\n",
      "print(\"출처:\", [doc.metadata[\"source\"] for doc in result[\"source_documents\"]])\n",
      "```\n",
      "\n",
      "위 예시는 **RAG**(Retrieval‑Augmented Generation) 형태의 가장 기본적인 흐름을 보여줍니다.  \n",
      "- 문서를 임베딩 → 벡터스토어에 저장  \n",
      "- 질문이 들어오면 관련 문서 4개를 검색 → LLM에게 프롬프트와 함께 전달 → 답변 생성  \n",
      "\n",
      "---\n",
      "\n",
      "## 실제 적용 사례\n",
      "\n",
      "| 분야 | 활용 예시 |\n",
      "|------|-----------|\n",
      "| **고객지원 챗봇** | 고객 문의를 실시간으로 검색·답변. `ConversationBufferMemory` 로 대화 흐름 유지. |\n",
      "| **코드 자동생성** | `LLM` + `Tool`(GitHub API) 로 코드 스니펫을 검색·생성, PR 자동 생성. |\n",
      "| **데이터 분석** | `PythonREPLTool` 과 결합해 자연어로 분석 질문 → Python 코드를 실행하고 결과 반환. |\n",
      "| **법률·의료 지식베이스** | 민감한 문서들을 벡터스토어에 보관하고, RAG 로 정확한 근거와 함께 답변 제공. |\n",
      "| **멀티모달 어시스턴트** | 이미지 캡션 생성 + 텍스트 요약을 하나의 체인으로 연결해 보고서 자동작성. |\n",
      "| **워크플로 자동화** | `LangGraph` 로 “이메일 → 일정 확인 → 회의실 예약” 같은 복합 프로세스를 상태 머신으로 구현. |\n",
      "\n",
      "---\n",
      "\n",
      "## 시작하기 위한 팁\n",
      "\n",
      "1. **프로젝트 목표를 명확히**  \n",
      "   - 단순 텍스트 생성 → `LLM`만 사용.  \n",
      "   - 외부 지식·도구 연동 → `Retriever`, `Tool`, `Agent` 도입.\n",
      "\n",
      "2. **프롬프트 템플릿을 먼저 설계**  \n",
      "   - 변수와 설명을 명확히 적어두면 체인 재사용이 쉬워집니다.\n",
      "\n",
      "3. **메모리와 컨텍스트 관리**  \n",
      "   - 대화형 앱이라면 `ConversationBufferMemory` 로 히스토리를 자동 삽입.  \n",
      "   - 토큰 제한이 있을 경우 `ConversationSummaryMemory` 로 요약을 적용.\n",
      "\n",
      "4. **벡터스토어 선택**  \n",
      "   - 로컬 테스트 → `FAISS` 혹은 `Chroma`.  \n",
      "   - 프로덕션 → `Pinecone`, `Weaviate`, `Milvus` 등 클라우드 기반을 권장.\n",
      "\n",
      "5. **에이전트 사용 시**  \n",
      "   - 도구를 **명확히 정의**하고, `description`에 사용 목적을 상세히 적어야 LLM이 올바르게 선택합니다.\n",
      "\n",
      "6. **배포**  \n",
      "   - `LangServe` 로 FastAPI 기반 엔드포인트를 한 줄 코드로 만들 수 있습니다.  \n",
      "   - `Dockerfile`에 `langserve`와 `uvicorn`을 포함해 컨테이너화하면 CI/CD 파이프라인에 쉽게 연결.\n",
      "\n",
      "---\n",
      "\n",
      "## 간단한 LangServe 예시\n",
      "\n",
      "```python\n",
      "# app.py\n",
      "from fastapi import FastAPI\n",
      "from langserve import add_routes\n",
      "from langchain.chains import LLMChain\n",
      "from langchain.prompts import PromptTemplate\n",
      "from langchain.llms import OpenAI\n",
      "\n",
      "app = FastAPI()\n",
      "\n",
      "prompt = PromptTemplate.from_template(\"다음 문장을 한국어로 번역해 주세요: {text}\")\n",
      "chain = LLMChain(llm=OpenAI(model=\"gpt-4o-mini\"), prompt=prompt)\n",
      "\n",
      "add_routes(app, chain, path=\"/translate\")\n",
      "```\n",
      "\n",
      "```bash\n",
      "# 실행\n",
      "uvicorn app:app --host 0.0.0.0 --port 8000\n",
      "# 이제 POST /translate {\"text\":\"Hello, world!\"} 로 번역 API 사용 가능\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "## 마무리\n",
      "\n",
      "- **LangChain**은 LLM을 **프롬프트 수준**이 아니라 **시스템 수준**에서 활용하도록 설계된 **모듈형 프레임워크**입니다.  \n",
      "- `Chain`, `Agent`, `Memory`, `Retriever` 등 핵심 컴포넌트를 조합하면 **검색·계산·데이터베이스·멀티모달** 등 다양한 기능을 갖춘 **지능형 어플리케이션**을 빠르게 구축할 수 있습니다.  \n",
      "- 오픈소스이며 활발한 커뮤니티가 지속적으로 새로운 도구·템플릿을 제공하므로, 프로젝트 초기부터 최신 기능을 적용하기 용이합니다.\n",
      "\n",
      "궁금한 점이나 구체적인 구현 예시가 필요하면 언제든 알려 주세요! 🚀\n"
     ]
    }
   ],
   "source": [
    "print(type(response))\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mylangchain-app-75wTJiYg-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
