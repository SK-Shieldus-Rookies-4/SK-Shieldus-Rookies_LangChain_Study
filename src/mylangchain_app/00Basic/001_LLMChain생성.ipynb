{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed0f96f1-910f-438f-876f-9eff119c2b0a",
   "metadata": {
    "id": "ed0f96f1-910f-438f-876f-9eff119c2b0a"
   },
   "source": [
    "### LLM Chain 만들기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5b1e2f-9d67-4d01-9a8c-83ced6b711a9",
   "metadata": {
    "id": "5a5b1e2f-9d67-4d01-9a8c-83ced6b711a9"
   },
   "source": [
    "## 1. 환경 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03b7854-f96a-47fc-b3c7-b2bdfb55df81",
   "metadata": {
    "id": "b03b7854-f96a-47fc-b3c7-b2bdfb55df81"
   },
   "source": [
    "### 1) 라이브러리 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd87a33-0a37-461b-8f37-3c142e60b1f6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4cd87a33-0a37-461b-8f37-3c142e60b1f6",
    "outputId": "c96ed02d-19b7-4e90-d92e-1ae52895e303"
   },
   "outputs": [],
   "source": [
    "# poetry add python-dotenv langchain langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55152049-e9e5-4952-8e19-409f58cf3ac9",
   "metadata": {
    "id": "55152049-e9e5-4952-8e19-409f58cf3ac9"
   },
   "source": [
    "### 2) OpenAI 인증키 설정\n",
    "https://openai.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b76f68a8-4745-4377-8057-6090b87377d1",
   "metadata": {
    "id": "b76f68a8-4745-4377-8057-6090b87377d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gsk_o\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# .env 파일을 불러와서 환경 변수로 설정\n",
    "load_dotenv(dotenv_path='.env')\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e09aaca6-5aa2-4b52-bbfc-196e808dc5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3.27\n"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "print(langchain.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc01c50a-32cf-49af-891a-f9b17fa0bd6c",
   "metadata": {
    "id": "fc01c50a-32cf-49af-891a-f9b17fa0bd6c"
   },
   "source": [
    "## 2. LLM Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23729d10-9600-415b-b7d1-f954665224e3",
   "metadata": {
    "id": "23729d10-9600-415b-b7d1-f954665224e3"
   },
   "source": [
    "### 1) Prompt + LLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "on0y4xF8VoyE",
   "metadata": {
    "id": "on0y4xF8VoyE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# model\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# chain 실행\n",
    "result = llm.invoke(\"인공지능 모델의 학습 원리에 대하여 쉽게 설명해 주세요.\")\n",
    "print(type(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4dc4accf-c927-40a3-ba2c-f891c94c34f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='인공지능 모델의 학습 원리는 다음과 같습니다.\\n\\n1.  **데이터 수집**: 인공지능 모델은 학습을 위해 다양한 데이터를 수집합니다. 이 데이터는 모델이 학습할 수 있는 형태로 가공됩니다.\\n\\n2.  **데이터 전처리**: 수집된 데이터는 모델이 학습할 수 있는 형태로 가공됩니다. 예를 들어, 이미지 데이터는 픽셀 값으로 변환되고, 텍스트 데이터는 단어 또는 문장으로 변환됩니다.\\n\\n3.  **모델 초기화**: 인공지능 모델은 학습을 시작하기 전에 초기화됩니다. 이 과정에서는 모델의 가중치와 편향이 무작위로 설정됩니다.\\n\\n4.  **학습**: 모델은 수집된 데이터를 사용하여 학습합니다. 학습 과정에서는 모델이 입력 데이터에 대해 예측을 하고, 예측 결과와 실제 값 사이의 오차를 계산합니다.\\n\\n5.  **오차 역전파**: 오차 역전파는 모델의 예측 결과와 실제 값 사이의 오차를 계산하고, 이 오차를 최소화하기 위해 모델의 가중치와 편향을 업데이트하는 과정입니다. 이 과정은 모델이 학습할 수 있는 방향으로 진행됩니다.\\n\\n6.  **모델 업데이트**: 오차 역전파를 통해 계산된 오차를 최소화하기 위해 모델의 가중치와 편향이 업데이트됩니다. 이 과정은 모델이 학습할 수 있는 방향으로 진행됩니다.\\n\\n7.  **반복 학습**: 모델은 수집된 데이터를 사용하여 반복적으로 학습합니다. 이 과정은 모델이 원하는 수준의 정확도에 도달할 때까지 반복됩니다.\\n\\n8.  **모델 평가**: 모델의 학습이 완료되면, 모델의 성능을 평가합니다. 이 과정에서는 모델의 예측 결과와 실제 값 사이의 오차를 계산하고, 모델의 성능을 측정합니다.\\n\\n9.  **모델 배포**: 모델의 성능이 만족할 만한 수준이면, 모델을 배포합니다. 이 과정에서는 모델을 실제 환경에 적용하고, 모델의 성능을 모니터링합니다.\\n\\n이러한 과정을 통해 인공지능 모델은 학습하고, 원하는 수준의 정확도에 도달할 수 있습니다.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 413, 'prompt_tokens': 24, 'total_tokens': 437, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'queue_time': 0.207604142, 'prompt_time': 0.000465781, 'completion_time': 0.969645949, 'total_time': 0.97011173}, 'model_name': 'meta-llama/llama-4-scout-17b-16e-instruct', 'system_fingerprint': 'fp_79da0e0073', 'id': 'chatcmpl-29d0da02-34c7-4de0-9f89-b2ba915382b2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None} id='run--48c6885c-68bd-457f-bb18-1348ff8e37fe-0' usage_metadata={'input_tokens': 24, 'output_tokens': 413, 'total_tokens': 437, 'input_token_details': {}, 'output_token_details': {}}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "WzcZy4PruV1n",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "WzcZy4PruV1n",
    "outputId": "18ecc8f9-5748-4b16-cb07-4a0f7a01fb5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인공지능 모델의 학습 원리는 다음과 같습니다.\n",
      "\n",
      "1.  **데이터 수집**: 인공지능 모델은 학습을 위해 다양한 데이터를 수집합니다. 이 데이터는 모델이 학습할 수 있는 형태로 가공됩니다.\n",
      "\n",
      "2.  **데이터 전처리**: 수집된 데이터는 모델이 학습할 수 있는 형태로 가공됩니다. 예를 들어, 이미지 데이터는 픽셀 값으로 변환되고, 텍스트 데이터는 단어 또는 문장으로 변환됩니다.\n",
      "\n",
      "3.  **모델 초기화**: 인공지능 모델은 학습을 시작하기 전에 초기화됩니다. 이 과정에서는 모델의 가중치와 편향이 무작위로 설정됩니다.\n",
      "\n",
      "4.  **학습**: 모델은 수집된 데이터를 사용하여 학습합니다. 학습 과정에서는 모델이 입력 데이터에 대해 예측을 하고, 예측 결과와 실제 값 사이의 오차를 계산합니다.\n",
      "\n",
      "5.  **오차 역전파**: 오차 역전파는 모델의 예측 결과와 실제 값 사이의 오차를 계산하고, 이 오차를 최소화하기 위해 모델의 가중치와 편향을 업데이트하는 과정입니다. 이 과정은 모델이 학습할 수 있는 방향으로 진행됩니다.\n",
      "\n",
      "6.  **모델 업데이트**: 오차 역전파를 통해 계산된 오차를 최소화하기 위해 모델의 가중치와 편향이 업데이트됩니다. 이 과정은 모델이 학습할 수 있는 방향으로 진행됩니다.\n",
      "\n",
      "7.  **반복 학습**: 모델은 수집된 데이터를 사용하여 반복적으로 학습합니다. 이 과정은 모델이 원하는 수준의 정확도에 도달할 때까지 반복됩니다.\n",
      "\n",
      "8.  **모델 평가**: 모델의 학습이 완료되면, 모델의 성능을 평가합니다. 이 과정에서는 모델의 예측 결과와 실제 값 사이의 오차를 계산하고, 모델의 성능을 측정합니다.\n",
      "\n",
      "9.  **모델 배포**: 모델의 성능이 만족할 만한 수준이면, 모델을 배포합니다. 이 과정에서는 모델을 실제 환경에 적용하고, 모델의 성능을 모니터링합니다.\n",
      "\n",
      "이러한 과정을 통해 인공지능 모델은 학습하고, 원하는 수준의 정확도에 도달할 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5c97fc",
   "metadata": {},
   "source": [
    "### 2) PromptTemplate + LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "SeNi_VXqYD-b",
   "metadata": {
    "id": "SeNi_VXqYD-b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.prompts.prompt.PromptTemplate'>\n",
      "input_variables=['input'] input_types={} partial_variables={} template='You are an expert in AI Expert. Answer the question. <Question>: {input}에 대해 쉽게 설명해주세요.'\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"You are an expert in AI Expert. Answer the question. <Question>: {input}에 대해 쉽게 설명해주세요.\")\n",
    "\n",
    "print(type(prompt))\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01WLucSpYjZt",
   "metadata": {
    "id": "01WLucSpYjZt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n",
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "content='인공지능 모델의 학습 원리는 사람의 뇌가 학습하는 원리와 유사합니다. \\n\\n기본적으로 인공지능 모델은 데이터를 통해 학습합니다. 예를 들어, 고양이와 강아지의 사진을 보여주며 이 사진들을 보고 고양이와 강아지를 구분하는 모델을 만든다고 가정해 봅시다.\\n\\n1. **데이터 수집**: 수많은 고양이와 강아지의 사진을 수집합니다. 이 사진들은 모델이 학습하는데 필요한 재료와 같습니다.\\n\\n2. **데이터 전처리**: 수집한 사진들을 모델이 이해할 수 있도록 숫자의 형태로 변환합니다. 예를 들어, 사진의 픽셀 값을 숫자로 바꾸는 과정입니다.\\n\\n3. **모델 초기화**: 처음에 모델은 고양이와 강아지에 대해 아무것도 모릅니다. 모델의 내부 매개변수들(가중치와 편향)은 무작위로 초기화됩니다.\\n\\n4. **학습 과정**: \\n   - 모델에 고양이 사진을 넣고 \"이것은 고양이다\"라고 알려줍니다.\\n   - 모델은 예측을 합니다. 예를 들어, \"이것은 강아지 같다\"고 예측할 수 있습니다.\\n   - 모델의 예측과 실제 값(고양이)을 비교하여 얼마나 틀렸는지 계산합니다. 이를 **손실 함수**를 통해 계산합니다.\\n   - 모델은 손실을 최소화하기 위해 내부 매개변수(가중치와 편향)를 조금씩 조정합니다. 이 과정을 **역전파**라고 하며, 이 때 **최적화 알고리즘**(예: 경사 하강법)을 사용합니다.\\n   - 이 과정을 많은 사진들로 반복합니다.\\n\\n5. **반복 학습**: 4번의 과정을 고양이와 강아지의 모든 사진들에 대해 여러 번 반복합니다. 모델은 매번 조금씩 더 나은 예측을 하게 됩니다.\\n\\n6. **모델 평가**: 학습이 끝난 후, 새로운 사진들로 모델의 성능을 평가합니다. 모델이 얼마나 정확하게 고양이와 강아지를 구분하는지 확인합니다.\\n\\n7. **튜닝 및 활용**: 모델의 성능이 만족스럽지 않다면, 더 많은 데이터를 수집하거나, 모델의 구조를 바꾸거나, 학습 파라미터를 조정하는 등 다양한 방법으로 모델을 개선할 수 있습니다.\\n\\n이렇게 인공지능 모델은 데이터를 통해 학습하며, 그 과정을 통해 특정 작업을 더 잘 수행하도록 발전합니다.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 464, 'prompt_tokens': 36, 'total_tokens': 500, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'queue_time': 0.205458706, 'prompt_time': 0.000700347, 'completion_time': 1.120418712, 'total_time': 1.121119059}, 'model_name': 'meta-llama/llama-4-scout-17b-16e-instruct', 'system_fingerprint': 'fp_79da0e0073', 'id': 'chatcmpl-269af34f-8d94-44cd-b22e-41eab3f18dc2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None} id='run--5963d4d7-ea03-4d91-8c43-6a6633299fab-0' usage_metadata={'input_tokens': 36, 'output_tokens': 464, 'total_tokens': 500, 'input_token_details': {}, 'output_token_details': {}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    temperature=0.7\n",
    ")\n",
    "# chain 연결 (LCEL)\n",
    "chain = prompt | llm\n",
    "print(type(chain))\n",
    "\n",
    "# chain 호출\n",
    "result = chain.invoke({\"input\": \"인공지능 모델의 학습 원리\"})\n",
    "print(type(result))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "170ec878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인공지능 모델의 학습 원리는 사람의 뇌가 학습하는 원리와 유사합니다. \n",
      "\n",
      "기본적으로 인공지능 모델은 데이터를 통해 학습합니다. 예를 들어, 고양이와 강아지의 사진을 보여주며 이 사진들을 보고 고양이와 강아지를 구분하는 모델을 만든다고 가정해 봅시다.\n",
      "\n",
      "1. **데이터 수집**: 수많은 고양이와 강아지의 사진을 수집합니다. 이 사진들은 모델이 학습하는데 필요한 재료와 같습니다.\n",
      "\n",
      "2. **데이터 전처리**: 수집한 사진들을 모델이 이해할 수 있도록 숫자의 형태로 변환합니다. 예를 들어, 사진의 픽셀 값을 숫자로 바꾸는 과정입니다.\n",
      "\n",
      "3. **모델 초기화**: 처음에 모델은 고양이와 강아지에 대해 아무것도 모릅니다. 모델의 내부 매개변수들(가중치와 편향)은 무작위로 초기화됩니다.\n",
      "\n",
      "4. **학습 과정**: \n",
      "   - 모델에 고양이 사진을 넣고 \"이것은 고양이다\"라고 알려줍니다.\n",
      "   - 모델은 예측을 합니다. 예를 들어, \"이것은 강아지 같다\"고 예측할 수 있습니다.\n",
      "   - 모델의 예측과 실제 값(고양이)을 비교하여 얼마나 틀렸는지 계산합니다. 이를 **손실 함수**를 통해 계산합니다.\n",
      "   - 모델은 손실을 최소화하기 위해 내부 매개변수(가중치와 편향)를 조금씩 조정합니다. 이 과정을 **역전파**라고 하며, 이 때 **최적화 알고리즘**(예: 경사 하강법)을 사용합니다.\n",
      "   - 이 과정을 많은 사진들로 반복합니다.\n",
      "\n",
      "5. **반복 학습**: 4번의 과정을 고양이와 강아지의 모든 사진들에 대해 여러 번 반복합니다. 모델은 매번 조금씩 더 나은 예측을 하게 됩니다.\n",
      "\n",
      "6. **모델 평가**: 학습이 끝난 후, 새로운 사진들로 모델의 성능을 평가합니다. 모델이 얼마나 정확하게 고양이와 강아지를 구분하는지 확인합니다.\n",
      "\n",
      "7. **튜닝 및 활용**: 모델의 성능이 만족스럽지 않다면, 더 많은 데이터를 수집하거나, 모델의 구조를 바꾸거나, 학습 파라미터를 조정하는 등 다양한 방법으로 모델을 개선할 수 있습니다.\n",
      "\n",
      "이렇게 인공지능 모델은 데이터를 통해 학습하며, 그 과정을 통해 특정 작업을 더 잘 수행하도록 발전합니다.\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56848a4c",
   "metadata": {},
   "source": [
    "### 3) PromptTemplate + LLM(invoke()) + StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d1e9009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n",
      "<class 'str'>\n",
      "인공지능 모델의 학습 원리는 사람의 뇌가 학습하는 원리와 유사합니다. 예를 들어, 고양이를 인식하는 모델을 개발한다고 가정해 보겠습니다.\n",
      "\n",
      "1. **데이터 수집**: 수많은 고양이 및 고양이가 아닌 동물의 사진 데이터를 수집합니다.\n",
      "\n",
      "2. **데이터 전처리**: 수집한 데이터를 모델이 이해할 수 있도록 숫자로 변환하는 과정을 거칩니다.\n",
      "\n",
      "3. **모델 초기화**: 모델은 처음에 고양이를 인식하는 방법을 모릅니다. 모델의 가중치와 편향은 무작위로 초기화됩니다.\n",
      "\n",
      "4. **예측**: 모델에 고양이 사진과 아닌 사진을 보여주면, 모델은 고양이인지 아닌지 예측합니다. 이때 모델의 예측 결과는 대부분 부정확합니다.\n",
      "\n",
      "5. **손실 함수 계산**: 모델의 예측 결과와 실제 레이블(고양이 또는 고양이 아님) 사이의 오류를 계산합니다. 이를 손실(loss)이라고 합니다.\n",
      "\n",
      "6. **역전파**: 손실을 최소화하기 위해, 모델의 각 파라미터(가중치와 편향)가 손실에 미치는 영향을 계산합니다. 이 과정은 역전파(backpropagation)라고 합니다.\n",
      "\n",
      "7. **최적화**: 역전파를 통해 얻은 정보를 바탕으로 모델의 파라미터를 조정합니다. 이 과정은 경사 하강법(gradient descent) 또는 그 변형들(예: Adam, RMSprop 등)을 통해 이루어집니다. 이 과정을 통해 모델은 고양이를 더 잘 인식하도록 학습합니다.\n",
      "\n",
      "8. **반복**: 4~7번의 과정을 많은 양의 데이터에 대해 반복합니다. 반복할수록 모델은 고양이를 더 잘 인식하게 됩니다.\n",
      "\n",
      "9. **평가**: 모델의 성능을 평가합니다. 평가 데이터에 대해 모델의 예측 결과가 실제와 얼마나 일치하는지 확인합니다.\n",
      "\n",
      "10. **튜닝**: 필요하다면, 하이퍼파라미터(예: 학습률, 배치 크기 등)를 조정하여 모델의 성능을 개선합니다.\n",
      "\n",
      "이 과정을 통해 인공지능 모델은 주어진 데이터를 기반으로 학습하고, 새로운 데이터에 대해서도 좋은 성능을 발휘할 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 1. 컴포넌트 정의\n",
    "prompt = PromptTemplate.from_template(\"You are an expert in AI Expert. Answer the question. <Question>: {input}에 대해 쉽게 설명해주세요.\")\n",
    "\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# 2. chain 생성 (LCEL)\n",
    "chain = prompt | llm | output_parser\n",
    "print(type(chain))\n",
    "\n",
    "# 3. chain의 invoke 호출\n",
    "result = chain.invoke({\"input\": \"인공지능 모델의 학습 원리\"})\n",
    "print(type(result))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d997b16",
   "metadata": {},
   "source": [
    "### 4) PromptTemplate + LLM(stream()) + StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "684654e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인공지능 모델의 학습 원리는 사람의 뇌가 학습하는 원리와 유사합니다. 컴퓨터가 데이터를 통해 배우고, 이를 기반으로 예측이나 판단을 내리는 과정을 거칩니다.\n",
      "\n",
      "1. **데이터 수집**: 우선, 인공지능 모델을 학습시키기 위해 관련된 데이터를 수집합니다. 이 데이터는 문제의 성격에 따라 달라지며, 이미지, 텍스트, 오디오 등 다양한 형태가 될 수 있습니다.\n",
      "\n",
      "2. **데이터 전처리**: 수집된 데이터는 학습에 적합한 형태로 변환되어야 합니다. 예를 들어, 이미지 데이터의 경우, 픽셀 값으로 변환하거나, 텍스트 데이터의 경우, 단어의 빈도나 의미를 수치로 표현하는 벡터로 변환하는 과정 등이 이에 해당합니다.\n",
      "\n",
      "3. **모델 선택**: 인공지능 모델에는 여러 종류가 있으며, 문제의 성격에 따라 적합한 모델을 선택해야 합니다. 예를 들어, 이미지 분류 문제에는 합성곱 신경망(CNN), 자연어 처리 문제에는 순환 신경망(RNN)이나 트랜스포머 모델이 적합합니다.\n",
      "\n",
      "4. **학습**: 선택된 모델에 데이터를 입력하여 모델의 파라미터(가중치와 편향)를 조정하는 과정을 학습이라고 합니다. 이 과정에서는 최적화 알고리즘(예: 경사 하강법)을 사용하여 모델의 예측 결과와 실제 값 사이의 오류를 최소화합니다.\n",
      "\n",
      "5. **평가**: 학습된 모델의 성능을 평가하기 위해, 별도의 테스트 데이터를 사용하여 모델의 정확도, 정밀도, 재현율 등을 측정합니다.\n",
      "\n",
      "6. **튜닝**: 모델의 성능을 향상시키기 위해, 하이퍼파라미터(예: 학습률, 배치 크기) 등을 조정하는 과정을 거칩니다.\n",
      "\n",
      "예를 들어, 어린 아이에게 고양이와 개의 사진을 보여주고, 고양이와 개를 구별하도록 가르치는 것과 유사하다고 할 수 있습니다. 처음에는 아이가 고양이와 개의 특징을 잘 모르기 때문에, 여러 번의 예시를 통해 고양이는 귀가 뾰족하고, 개는 귀가 쳐지는 것이라는 것을 배웁니다. 인공지능 모델도 이와 유사하게, 많은 데이터를 통해 패턴을 학습하고, 이를 기반으로 새로운 이미지가 고양이인지 개인지 판별할 수 있습니다.\n",
      "\n",
      "이러한 학습 원리를 통해 인공지능 모델은 주어진 문제에 대해 점점 더 정확한 예측을 할 수 있게 됩니다."
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 1. 컴포넌트 정의\n",
    "prompt = PromptTemplate.from_template(\"You are an expert in AI Expert. Answer the question. <Question>: {input}에 대해 쉽게 설명해주세요.\")\n",
    "\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "lm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# chain 연결 (LCEL)\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# 스트리밍 출력을 위한 요청\n",
    "answer = chain.stream({\"input\": \"인공지능 모델의 학습 원리\"})\n",
    "# 스트리밍 출력\n",
    "#print(answer)\n",
    "\n",
    "for token in answer:\n",
    "    # 스트림에서 받은 데이터의 내용을 출력합니다. 줄바꿈 없이 이어서 출력하고, 버퍼를 즉시 비웁니다.\n",
    "    print(token, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0188674-915f-41af-ac46-56f9f54289b0",
   "metadata": {
    "id": "b0188674-915f-41af-ac46-56f9f54289b0"
   },
   "source": [
    "##### 2) Multiple Chains\n",
    "* Multi Chain을 활용한 영화 추천 및 줄거리 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "31678c55-38a8-4ca2-b437-9d4495946b0a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "31678c55-38a8-4ca2-b437-9d4495946b0a",
    "outputId": "7ee83878-5d1a-45e3-f033-100da33f3ee9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      " ===> 추천된 영화:\n",
      "**《무간도》(2002, 홍콩)**  \n",
      "감독: 유위강(Andrew Lau) & 류위덕(Alan Mak)\n",
      "\n",
      "“당신은 경찰인가, 조직원인가?”  \n",
      "한 명의 경찰 요원이 조직에 잠입하고, 한 명의 조직원이 경찰로 위장하는 ‘이중 스파이’ 구조를 통해 선악·신분·자아의 경계를 끊임없이 뒤집는 작품입니다. 2000년대 홍콩 누아르의 정수이자, 헐리우드 리메이크(『디파티드』)까지 탄생시킨 명작이죠. 템포감 있는 편집, 비 오는 밤의 야경, 마지막 엘리베이터 장면까지… 잊히지 않는 명장면이 많습니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Step 1: 사용자가 입력한 장르에 따라 영화 추천\n",
    "prompt1 = ChatPromptTemplate.from_template(\"{genre} 장르에서 추천할 만한 영화를 한 편 알려주세요.\")\n",
    "\n",
    "# Step 2: 추천된 영화의 줄거리를 요약\n",
    "prompt2 = ChatPromptTemplate.from_template(\"{movie} 추천한 영화의 제목을 먼저 알려주시고, 줄을 바꾸어서 영화의 정보(제목,감독,캐스팅,줄거리)를 알려 주세요\")\n",
    "\n",
    "# OpenAI 모델 사용\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    # model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    model=\"moonshotai/kimi-k2-instruct-0905\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# 체인 1: 영화 추천 (입력: 장르 → 출력: 영화 제목)\n",
    "chain1 = prompt1 | llm | StrOutputParser()\n",
    "\n",
    "# Step 1: 사용자가 입력한 장르에 따라 영화 추천\n",
    "movie = chain1.invoke({\"genre\": \"Drama\"})  # 영화 제목 얻기\n",
    "\n",
    "print(type(movie))\n",
    "print(\" ===> 추천된 영화:\")  # movie 값 출력\n",
    "print(movie)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "16718b76-f59d-48f7-906f-5d2371417803",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "16718b76-f59d-48f7-906f-5d2371417803",
    "outputId": "6e3371cd-d294-4be7-a868-2eae5ee6e5de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first={\n",
      "  movie: ChatPromptTemplate(input_variables=['genre'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['genre'], input_types={}, partial_variables={}, template='{genre} 장르에서 추천할 만한 영화를 한 편 알려주세요.'), additional_kwargs={})])\n",
      "         | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x122e5af50>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x122e5b150>, root_client=<openai.OpenAI object at 0x122e59950>, root_async_client=<openai.AsyncOpenAI object at 0x122e5ae50>, model_name='moonshotai/kimi-k2-instruct-0905', temperature=0.7, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://api.groq.com/openai/v1')\n",
      "         | StrOutputParser()\n",
      "} middle=[ChatPromptTemplate(input_variables=['movie'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['movie'], input_types={}, partial_variables={}, template='{movie} 추천한 영화의 제목을 먼저 알려주시고, 줄을 바꾸어서 영화의 정보(제목,감독,캐스팅,줄거리)를 알려 주세요'), additional_kwargs={})]), ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x122e5af50>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x122e5b150>, root_client=<openai.OpenAI object at 0x122e59950>, root_async_client=<openai.AsyncOpenAI object at 0x122e5ae50>, model_name='moonshotai/kimi-k2-instruct-0905', temperature=0.7, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://api.groq.com/openai/v1')] last=StrOutputParser()\n",
      "\n",
      "🔹 영화 줄거리 요약:\n",
      " 『그래비티』\n",
      "\n",
      "제목: 그래비티  \n",
      "감독: 알폰수 쿠아론  \n",
      "캐스팅: 산드라 블록(레이언 스톤), 조지 클루니(맷 코왈스키)  \n",
      "줄거리: 우주 유리 수리 작업 중 우주 쓰레기 사고로 셔틀이 파괴된 뒤, 의료 엔지니어 레이언은 우주의 완전한 고립 속에서 생존과 귀환을 위한 사투를 벌인다.\n"
     ]
    }
   ],
   "source": [
    "# 체인 2: 줄거리 요약 (입력: 영화 제목 → 출력: 줄거리)\n",
    "chain2 = (\n",
    "    {\"movie\": chain1}  # chain1의 출력을 movie 변수로 전달\n",
    "    | prompt2\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "print(chain2)\n",
    "\n",
    "# 실행: \"SF\" 장르의 영화 추천 및 줄거리 요약\n",
    "response = chain2.invoke({\"genre\": \"Drama\"})\n",
    "print(\"\\n🔹 영화 줄거리 요약:\\n\", response) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb684fd",
   "metadata": {},
   "source": [
    "##### chain1과 chain2에서 영화 제목이 일관되게 전달 되도록 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e30883ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 영화 줄거리 요약:\n",
      "('쇼생크 탈출\\n'\n",
      " '\\n'\n",
      " '제목: 쇼생크 탈출 (The Shawshank Redemption)  \\n'\n",
      " '감독: 프랭크 다라본트  \\n'\n",
      " '출연: 팀 로빈스(앤디 듀프레인), 모건 프리먼(레드), 밥 건턴(워든 노튼)  \\n'\n",
      " '줄거리: 1947년, 아내와 그녀의 정부를 살해했다는 누명을 쓴 은행원 앤디는 쇼생크 교도소에 무기징역으로 수감된다. 차분하고 지적인 '\n",
      " '그는 교도소 내에서 우연한 기회를 통해 감방 간부들의 세금 업무를 도와주며 존재감을 얻고, 동시에 19년간이나 자신만의 탈옥 계획을 '\n",
      " '진행한다. 오랜 세월 함께한 죄수 ‘레드’와의 깊은 우정, 그리고 끝까지 포기하지 않은 희망이 만들어낸 자유의 감동적인 결말을 그린다.')\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "# Step 1: 사용자가 입력한 장르에 따라 영화 추천\n",
    "prompt1 = ChatPromptTemplate.from_template(\"{genre} 장르에서 추천할 만한 영화를 한 편 알려주세요.\")\n",
    "\n",
    "# Step 2: 추천된 영화의 줄거리를 요약\n",
    "prompt2 = ChatPromptTemplate.from_template(\"{movie} 추천한 영화의 제목을 먼저 알려주시고, 줄을 바꾸어서 영화의 정보(제목,감독,캐스팅,줄거리)를 알려 주세요.\")\n",
    "\n",
    "# OpenAI 모델 사용\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    # model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    model=\"moonshotai/kimi-k2-instruct-0905\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# 체인 1: 영화 추천 (입력: 장르 → 출력: 영화 제목)\n",
    "chain1 = prompt1 | llm | StrOutputParser()\n",
    "\n",
    "# 체인 2: 줄거리 요약 (입력: 영화 제목 → 출력: 줄거리)\n",
    "chain2 = (\n",
    "    {\"movie\": chain1}  # chain1의 출력을 movie 변수로 전달\n",
    "    | prompt2\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 실행: \"Drama\" 장르의 영화 추천 및 줄거리 요약\n",
    "response = chain2.invoke({\"genre\": \"Drama\"})\n",
    "print(\"\\n🔹 영화 줄거리 요약:\")\n",
    "pprint(response)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "mylangchain-app-75wTJiYg-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
