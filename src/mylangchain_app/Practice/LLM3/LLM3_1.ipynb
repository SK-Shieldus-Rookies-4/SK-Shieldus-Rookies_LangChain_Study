{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedb7a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ (ì£¼ì„ ì²˜ë¦¬ - í•„ìš” ì‹œ ì£¼ì„ í•´ì œ í›„ ì‹¤í–‰)\n",
    "# !pip install -q langchain langchain-community langchain-upstage pypdf faiss-cpu python-dotenv\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_upstage import ChatUpstage\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_upstage import UpstageEmbeddings\n",
    "# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ (API í‚¤ ì„¤ì •)\n",
    "# UPSTAGE_API_KEYê°€ .env íŒŒì¼ì— ì„¤ì •ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.\n",
    "load_dotenv()\n",
    "\n",
    "# ê¸°ì¡´: load_dotenv() í›„\n",
    "UPSTAGE_API_KEY = os.getenv(\"UPSTAGE_API_KEY\") \n",
    "# print(UPSTAGE_API_KEY[30:]) # ë¡œë“œ í™•ì¸\n",
    "\n",
    "# ---\n",
    "## 0ë‹¨ê³„: ë¬¸ì„œ ë¡œë“œ\n",
    "# ---\n",
    "# íŒŒì¼ ê²½ë¡œê°€ í”„ë¡œì íŠ¸ ë£¨íŠ¸ì˜ 'data' í´ë” ì•ˆì— ìˆë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤.\n",
    "# ì‹¤ì œ ê²½ë¡œì— ë§ê²Œ '../data/ì½˜í…ì¸ ë¶„ìŸí•´ê²°_ì‚¬ë¡€.pdf'ë¥¼ ìˆ˜ì •í•´ì•¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "FILE_PATH = '../data/ì½˜í…ì¸ ë¶„ìŸí•´ê²°_ì‚¬ë¡€.pdf'\n",
    "\n",
    "try:\n",
    "    # 0ë‹¨ê³„: ë¬¸ì„œ ë¡œë“œ\n",
    "    print(\"âœ… 0ë‹¨ê³„: ë¬¸ì„œ ë¡œë“œ ì‹œì‘...\")\n",
    "    loader = PyPDFLoader(FILE_PATH)\n",
    "    documents = loader.load()\n",
    "    print(f\"   -> ì´ {len(documents)} í˜ì´ì§€ì˜ ë¬¸ì„œë¥¼ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"âŒ ì˜¤ë¥˜: íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”: {FILE_PATH}\")\n",
    "    # íŒŒì¼ì´ ì—†ì„ ê²½ìš° ì´í›„ ë‹¨ê³„ë¥¼ ê±´ë„ˆë›°ê¸° ìœ„í•´ ì¢…ë£Œ\n",
    "    # exit() \n",
    "except Exception as e:\n",
    "    print(f\"âŒ ë¬¸ì„œ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "    # exit()\n",
    "\n",
    "# ---\n",
    "## 1ë‹¨ê³„: ë¬¸ì„œ ë¶„í•  ì„¤ì • ë° ì‹¤í–‰\n",
    "# ---\n",
    "print(\"\\nâœ… 1ë‹¨ê³„: ë¬¸ì„œ ë¶„í• (Chunking) ì‹œì‘...\")\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,        # ë²•ë¥  ì‚¬ë¡€ëŠ” 1200-1800ì ê¶Œì¥\n",
    "    chunk_overlap=100,      # ì‚¬ë¡€ ë§¥ë½ ë³´ì¡´ì„ ìœ„í•´ 200-400ì\n",
    "    separators=[\n",
    "        \"\\nã€ì‚¬ê±´ê°œìš”ã€‘\",    # ë²•ë¥  ë¬¸ì„œ ì„¹ì…˜ êµ¬ë¶„ì\n",
    "        \"\\nã€ìŸì ì‚¬í•­ã€‘\",    # ìŸì  ë¶€ë¶„ êµ¬ë¶„\n",
    "        \"\\nã€ì²˜ë¦¬ê²½ìœ„ã€‘\",    # ì²˜ë¦¬ ê³¼ì • êµ¬ë¶„\n",
    "        \"\\nã€ì²˜ë¦¬ê²°ê³¼ã€‘\",    # ê²°ê³¼ ë¶€ë¶„ êµ¬ë¶„\n",
    "        \"\\nâ– \", \"\\n\\n\", \"\\n\", \".\", \" \", \"\"\n",
    "    ],\n",
    "    length_function=len\n",
    ")\n",
    "split_documents = text_splitter.split_documents(documents)\n",
    "print(f\"   -> ë¶„í• ëœ ë¬¸ì„œ ì¡°ê°(chunks) ìˆ˜: {len(split_documents)}ê°œ\")\n",
    "\n",
    "\n",
    "# ---\n",
    "## 2ë‹¨ê³„: ì„ë² ë”© ëª¨ë¸ ì„¤ì • ë° ë²¡í„°ìŠ¤í† ì–´ ìƒì„±\n",
    "# ---\n",
    "print(\"\\nâœ… 2ë‹¨ê³„: ì„ë² ë”© ëª¨ë¸ ì„¤ì • ë° ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ì‹œì‘...\")\n",
    "# 2ë‹¨ê³„: ì„ë² ë”© ëª¨ë¸ ì„¤ì •\n",
    "embeddings = UpstageEmbeddings(model=\"solar-embedding-1-large\", upstage_api_key=UPSTAGE_API_KEY)\n",
    "\n",
    "# FAISS ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ë° ì„ë² ë”©\n",
    "# ì´ ê³¼ì •ì€ ì‹œê°„ì´ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "vectorstore = FAISS.from_documents(split_documents, embeddings)\n",
    "print(\"   -> FAISS ë²¡í„°ìŠ¤í† ì–´ ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# ---\n",
    "## 3ë‹¨ê³„: ê²€ìƒ‰ê¸° ì„¤ì •\n",
    "# ---\n",
    "print(\"\\nâœ… 3ë‹¨ê³„: ê²€ìƒ‰ê¸° ì„¤ì •...\")\n",
    "# 3ë‹¨ê³„: ê²€ìƒ‰ê¸° ì„¤ì •\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",       # ìœ ì‚¬ë„ ê²€ìƒ‰ ì‚¬ìš©\n",
    "    search_kwargs={\"k\": 3}          # ìƒìœ„ 5ê°œ ê´€ë ¨ ì‚¬ë¡€ ê²€ìƒ‰\n",
    ")\n",
    "print(\"   -> ê²€ìƒ‰ê¸°(Retriever)ê°€ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤. (ê²€ìƒ‰ ë°©ì‹: similarity, k: 5)\")\n",
    "\n",
    "\n",
    "# ---\n",
    "## 4ë‹¨ê³„: LLM ì„¤ì •\n",
    "# ---\n",
    "print(\"\\nâœ… 4ë‹¨ê³„: LLM ì„¤ì •...\")\n",
    "# 4ë‹¨ê³„: LLM ì„¤ì •\n",
    "llm = ChatUpstage(\n",
    "        model=\"solar-pro\",\n",
    "        upstage_api_key=UPSTAGE_API_KEY, # <-- í‚¤ ì§ì ‘ ì „ë‹¬\n",
    "        base_url=\"https://api.upstage.ai/v1\",\n",
    "        temperature=0.5\n",
    "    )\n",
    "print(\"   -> LLMì´ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤. (ëª¨ë¸: solar-pro, ì˜¨ë„: 0.5)\")\n",
    "\n",
    "\n",
    "# ---\n",
    "## 5ë‹¨ê³„: ë²•ë¥  ìë¬¸ í”„ë¡¬í”„íŠ¸ ì‘ì„±\n",
    "# ---\n",
    "print(\"\\nâœ… 5ë‹¨ê³„: ë²•ë¥  ìë¬¸ í”„ë¡¬í”„íŠ¸ ì‘ì„±...\")\n",
    "# 5ë‹¨ê³„: ë²•ë¥  ìë¬¸ í”„ë¡¬í”„íŠ¸ ì‘ì„±\n",
    "prompt_template = \"\"\"\n",
    "ë‹¹ì‹ ì€ ì½˜í…ì¸  ë¶„ì•¼ ì „ë¬¸ ë²•ë¥  ìë¬¸ê°€ì…ë‹ˆë‹¤.\n",
    "ì•„ë˜ ë¶„ìŸì¡°ì • ì‚¬ë¡€ë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•˜ê³  ì „ë¬¸ì ì¸ ë²•ë¥  ì¡°ì–¸ì„ ì œê³µí•´ì£¼ì„¸ìš”.\n",
    "\n",
    "ê´€ë ¨ ë¶„ìŸì‚¬ë¡€:\n",
    "{context}\n",
    "\n",
    "ìƒë‹´ ë‚´ìš©: {question}\n",
    "\n",
    "ë‹µë³€ ê°€ì´ë“œë¼ì¸:\n",
    "1. ì œì‹œëœ ì‚¬ë¡€ë“¤ì„ ê·¼ê±°ë¡œ ë‹µë³€í•˜ì„¸ìš”.\n",
    "2. ê´€ë ¨ ë²•ë ¹ì´ë‚˜ ì¡°í•­ì´ ìˆë‹¤ë©´ ëª…ì‹œí•˜ì„¸ìš”.\n",
    "3. ë¹„ìŠ·í•œ ì‚¬ë¡€ì˜ ì²˜ë¦¬ê²½ìœ„ì™€ ê²°ê³¼ë¥¼ ì°¸ê³ í•˜ì—¬ ì„¤ëª…í•˜ì„¸ìš”.\n",
    "4. ì‹¤ë¬´ì  í•´ê²°ë°©ì•ˆì„ ë‹¨ê³„ë³„ë¡œ ì œì‹œí•˜ì„¸ìš”.\n",
    "5. ì‚¬ë¡€ì— ì—†ëŠ” ë‚´ìš©ì€ \"ì œì‹œëœ ì‚¬ë¡€ì§‘ì—ì„œëŠ” í™•ì¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤\"ë¼ê³  ëª…ì‹œí•˜ì„¸ìš”.\n",
    "\n",
    "ì „ë¬¸ ë²•ë¥  ì¡°ì–¸:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=prompt_template,\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "print(\"   -> ë²•ë¥  ìë¬¸ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì‘ì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "\n",
    "# ---\n",
    "## 6ë‹¨ê³„: QA ì²´ì¸ ìƒì„±\n",
    "# ---\n",
    "print(\"\\nâœ… 6ë‹¨ê³„: QA ì²´ì¸ ìƒì„± ì‹œì‘...\")\n",
    "# 6ë‹¨ê³„: QA ì²´ì¸ ìƒì„±\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\", # ëª¨ë“  ë¬¸ì„œë¥¼ í•˜ë‚˜ì˜ í”„ë¡¬í”„íŠ¸ì— ë„£ì–´ ì²˜ë¦¬\n",
    "    retriever=retriever,\n",
    "    chain_type_kwargs={\"prompt\": prompt}, # ì‚¬ìš©ì ì •ì˜ í”„ë¡¬í”„íŠ¸ ì ìš©\n",
    "    return_source_documents=True # ì°¸ì¡° ë¬¸ì„œë„ í•¨ê»˜ ë°˜í™˜\n",
    ")\n",
    "print(\"   -> RetrievalQA ì²´ì¸ ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "\n",
    "# ---\n",
    "## 7ë‹¨ê³„: í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ ì‘ì„± ë° ì‹¤í–‰\n",
    "# ---\n",
    "print(\"\\nâœ… 7ë‹¨ê³„: í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ ì‘ì„± ë° ì‹¤í–‰ ì‹œì‘...\")\n",
    "test_questions = [\n",
    "    \"ì˜¨ë¼ì¸ ê²Œì„ì—ì„œ ì‹œìŠ¤í…œ ì˜¤ë¥˜ë¡œ ì•„ì´í…œì´ ì‚¬ë¼ì¡ŒëŠ”ë°, ê²Œì„íšŒì‚¬ê°€ ë³µêµ¬ë¥¼ ê±°ë¶€í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì–´ë–»ê²Œ í•´ê²°í•  ìˆ˜ ìˆë‚˜ìš”?\",\n",
    "    \"ì¸í„°ë„· ê°•ì˜ë¥¼ ì¤‘ë„ í•´ì§€í•˜ë ¤ê³  í•˜ëŠ”ë° ê³¼ë„í•œ ìœ„ì•½ê¸ˆì„ ìš”êµ¬ë°›ê³  ìˆìŠµë‹ˆë‹¤. ì •ë‹¹í•œê°€ìš”?\",\n",
    "    \"ë¯¸ì„±ë…„ìê°€ ë¶€ëª¨ ë™ì˜ ì—†ì´ ê²Œì„ ì•„ì´í…œì„ êµ¬ë§¤í–ˆìŠµë‹ˆë‹¤. í™˜ë¶ˆë°›ì„ ìˆ˜ ìˆëŠ” ë°©ë²•ì´ ìˆë‚˜ìš”?\"\n",
    "]\n",
    "\n",
    "def ask_question_and_print_result(question):\n",
    "    print(f\"\\n========================================================\")\n",
    "    print(f\"ğŸ” ì§ˆë¬¸: {question}\")\n",
    "    print(f\"========================================================\")\n",
    "    result = None  # result ë³€ìˆ˜ ë¯¸ë¦¬ ì„ ì–¸\n",
    "    try:\n",
    "        result = qa_chain.invoke({\"query\": question})  # ë˜ëŠ” {\"question\": question} ë“± í”„ë¡¬í”„íŠ¸ input_variablesì™€ ì¼ì¹˜\n",
    "        print(\"âœ… [ì „ë¬¸ ë²•ë¥  ì¡°ì–¸]\")\n",
    "        print(result['result'])\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ QA ì²´ì¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "    if result is not None:\n",
    "        print(\"\\nğŸ“œ [ì°¸ì¡° ë¬¸ì„œ (Source Documents)]\")\n",
    "        for i, doc in enumerate(result['source_documents']):\n",
    "            source = doc.metadata.get('source', 'Unknown')\n",
    "            page = doc.metadata.get('page', 'Unknown')\n",
    "            print(f\"  {i+1}. íŒŒì¼: {os.path.basename(source)}, í˜ì´ì§€: {page} (ì ìˆ˜: {doc.metadata.get('score', 'N/A')})\")\n",
    "    print(\"--------------------------------------------------------\")\n",
    "\n",
    "\n",
    "    \n",
    "    # ì°¸ì¡° ë¬¸ì„œ ì¶œë ¥\n",
    "    print(\"\\nğŸ“œ [ì°¸ì¡° ë¬¸ì„œ (Source Documents)]\")\n",
    "    for i, doc in enumerate(result['source_documents']):\n",
    "        # ë©”íƒ€ë°ì´í„°ì—ì„œ íŒŒì¼ ì´ë¦„ê³¼ í˜ì´ì§€ ë²ˆí˜¸ ì¶”ì¶œ ì‹œë„\n",
    "        source = doc.metadata.get('source', 'Unknown')\n",
    "        page = doc.metadata.get('page', 'Unknown')\n",
    "        print(f\"  {i+1}. íŒŒì¼: {os.path.basename(source)}, í˜ì´ì§€: {page} (ì ìˆ˜: {doc.metadata.get('score', 'N/A')})\")\n",
    "        # ë¬¸ì„œ ë‚´ìš© ì¼ë¶€ë¥¼ ë³´ì—¬ì¤„ ê²½ìš° (ë””ë²„ê¹… ëª©ì )\n",
    "        # print(f\"     ë‚´ìš© ìš”ì•½: {doc.page_content[:150]}...\")\n",
    "    print(\"--------------------------------------------------------\")\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ ì‹¤í–‰\n",
    "for question in test_questions:\n",
    "    ask_question_and_print_result(question)\n",
    "    \n",
    "\n",
    "# ---\n",
    "## 8ë‹¨ê³„: ë¶„ìŸ ìœ í˜• ë¶„ë¥˜ í•¨ìˆ˜ (ì°¸ê³ ìš©)\n",
    "# ---\n",
    "# ì´ í•¨ìˆ˜ëŠ” ì²´ì¸ ì‹¤í–‰ ì „ì— ì§ˆë¬¸ ìœ í˜•ì„ íŒŒì•…í•˜ì—¬ í”„ë¡¬í”„íŠ¸ ë˜ëŠ” ê²€ìƒ‰ ì „ëµì„ ì¡°ì •í•˜ëŠ” ë° í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "print(\"\\nâœ… 8ë‹¨ê³„: ë¶„ìŸ ìœ í˜• ë¶„ë¥˜ í•¨ìˆ˜ (ì°¸ê³ )\")\n",
    "def classify_dispute_type(query):\n",
    "    game_keywords = [\"ê²Œì„\", \"ì•„ì´í…œ\", \"ê³„ì •\", \"ìºë¦­í„°\", \"ë ˆë²¨\", \"ê¸¸ë“œ\", \"ì˜¨ë¼ì¸ê²Œì„\"]\n",
    "    elearning_keywords = [\"ê°•ì˜\", \"ì˜¨ë¼ì¸êµìœ¡\", \"ì´ëŸ¬ë‹\", \"ìˆ˜ê°•\", \"í™˜ë¶ˆ\", \"í™”ìƒêµìœ¡\"]\n",
    "    web_keywords = [\"ì›¹ì‚¬ì´íŠ¸\", \"ë¬´ë£Œì²´í—˜\", \"ìë™ê²°ì œ\", \"êµ¬ë…\", \"ì‚¬ì´íŠ¸\"]\n",
    "    \n",
    "    query_lower = query.lower()\n",
    "    \n",
    "    if any(keyword in query_lower for keyword in game_keywords):\n",
    "        return \"ê²Œì„\"\n",
    "    elif any(keyword in query_lower for keyword in elearning_keywords):\n",
    "        return \"ì´ëŸ¬ë‹\"\n",
    "    elif any(keyword in query_lower for keyword in web_keywords):\n",
    "        return \"ì›¹ì½˜í…ì¸ \"\n",
    "    else:\n",
    "        return \"ê¸°íƒ€\"\n",
    "\n",
    "# ë¶„ë¥˜ í•¨ìˆ˜ í…ŒìŠ¤íŠ¸\n",
    "test_query = \"ì˜¨ë¼ì¸ ê°•ì˜ í™˜ë¶ˆ ì ˆì°¨ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”.\"\n",
    "print(f\"   -> '{test_query}'ì˜ ë¶„ìŸ ìœ í˜•: {classify_dispute_type(test_query)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mylangchain-app-75wTJiYg-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
