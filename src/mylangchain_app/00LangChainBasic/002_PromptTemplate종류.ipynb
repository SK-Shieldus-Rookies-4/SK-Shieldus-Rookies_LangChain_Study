{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PromptTemplate \n",
    "* [PromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.prompt.PromptTemplate.html#langchain_core.prompts.prompt.PromptTemplate)\n",
    "* [ChatPromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html#langchain_core.prompts.chat.ChatPromptTemplate)\n",
    "* [ChatMessagePromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatMessagePromptTemplate.html#langchain_core.prompts.chat.ChatMessagePromptTemplate)\n",
    "* [FewShotPromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.few_shot.FewShotPromptTemplate.html#langchain_core.prompts.few_shot.FewShotPromptTemplate)\n",
    "* PartialPrompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# poetry add python-dotenv langchain langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gsk_o\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# .env 파일을 불러와서 환경 변수로 설정\n",
    "load_dotenv(dotenv_path='../.env')\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1) PromptTemplate 의 from_template() 함수 사용\n",
    "* 주로 LLM(텍스트 완성형 모델, ex. Ollama, GPT-3.5)과 함께 사용\n",
    "* 하나의 문자열 프롬프트를 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ChatGPT는 대규모 텍스트 데이터를 이용해 언어의 통계적 패턴을 학습합니다. 이를 위해 트랜스포머 구조의 신경망을 사용해 문맥을 '\n",
      " '고려한 토큰 예측 작업을 수행하고, 손실 함수를 최소화하도록 파라미터를 최적화합니다. 이렇게 사전학습된 모델에 인간 피드백을 활용한 '\n",
      " '강화학습(RLHF)을 추가해 대화 품질과 안전성을 높입니다.')\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from pprint import pprint\n",
    "\n",
    "template_text = \"{model_name} 모델의 학습 원리를 {count} 문장으로 한국어로 답변해 주세요.\"\n",
    "\n",
    "# PromptTemplate 인스턴스를 생성\n",
    "prompt_template = PromptTemplate.from_template(template_text)\n",
    "\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    # model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    model=\"openai/gpt-oss-120b\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "chain = prompt_template | llm | StrOutputParser()\n",
    "response = chain.invoke({\"model_name\":\"ChatGPT\", \"count\":3})\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2) PromptTemplate 결합하기\n",
    "* 동일한 Prompt 패턴을 사용하지만 여러 개의 질문을 작성해서 LLM을 실행할 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['count', 'language', 'model_name'] input_types={} partial_variables={} template='{model_name} 모델의 학습 원리를 {count} 문장으로 한국어로 답변해 주세요.\\n\\n 그리고 {model_name} 모델의 장점을 요약 정리해 주세요\\n\\n {model_name} 모델과 비슷한 AI 모델은 어떤 것이 있나요? 모델명은 {language}로 답변해 주세요.'\n",
      "('**ChatGPT 모델의 학습 원리 (3문장)**  \\n'\n",
      " '1. 대규모 텍스트 데이터를 사용해 **자기지도학습**(self‑supervised learning) 방식으로 사전 '\n",
      " '학습(pre‑training)을 수행합니다.  \\n'\n",
      " '2. 문맥을 예측하는 **마스크드 언어 모델링**(masked language modeling)과 **다음 토큰 '\n",
      " '예측**(next‑token prediction) 목표를 통해 언어의 구조와 의미를 내부에 압축합니다.  \\n'\n",
      " '3. 이후 특정 작업(예: 질문‑답변, 번역 등)에 맞게 **지도학습**(supervised fine‑tuning)이나 '\n",
      " '**강화학습**(RLHF, Reinforcement Learning from Human Feedback)으로 미세 조정하여 실용성을 '\n",
      " '높입니다.  \\n'\n",
      " '\\n'\n",
      " '---\\n'\n",
      " '\\n'\n",
      " '### ChatGPT 모델의 장점 요약  \\n'\n",
      " '- **다양한 언어와 주제에 대한 높은 이해도**: 방대한 텍스트 코퍼스로부터 일반적인 지식과 언어 규칙을 학습해, 여러 분야의 질문에 '\n",
      " '자연스럽게 답변할 수 있습니다.  \\n'\n",
      " '- **문맥 유지와 연속적인 대화**: 트랜스포머 기반의 어텐션 메커니즘 덕분에 이전 발화들을 기억하고 일관된 흐름의 대화를 이어갈 수 '\n",
      " '있습니다.  \\n'\n",
      " '- **사용자 피드백을 통한 지속적 개선**: RLHF와 같은 방법으로 인간 피드백을 반영해 안전성, 정확성, 친절성을 꾸준히 '\n",
      " '향상시킵니다.  \\n'\n",
      " '\\n'\n",
      " '---\\n'\n",
      " '\\n'\n",
      " '### ChatGPT와 비슷한 AI 모델 (영어 모델명)  \\n'\n",
      " '- **GPT‑4** (OpenAI)  \\n'\n",
      " '- **Claude** (Anthropic)  \\n'\n",
      " '- **LLaMA** (Meta)  \\n'\n",
      " '- **Gemini** (Google DeepMind)  \\n'\n",
      " '- **Mistral** (Mistral AI)  \\n'\n",
      " '- **Phi‑2** (Microsoft)  \\n'\n",
      " '- **BLOOM** (BigScience)  \\n'\n",
      " '- **Cohere Command** (Cohere)  \\n'\n",
      " '\\n'\n",
      " '이 모델들은 모두 대규모 언어 모델(LLM) 기술을 기반으로 하며, 텍스트 생성, 질문‑답변, 요약 등 다양한 자연어 처리 작업에 '\n",
      " '활용됩니다.')\n"
     ]
    }
   ],
   "source": [
    "template_text = \"{model_name} 모델의 학습 원리를 {count} 문장으로 한국어로 답변해 주세요.\"\n",
    "\n",
    "# PromptTemplate 인스턴스를 생성\n",
    "prompt_template = PromptTemplate.from_template(template_text)\n",
    "\n",
    "# 템플릿에 값을 채워서 프롬프트를 완성\n",
    "filled_prompt = prompt_template.format(model_name=\"ChatGPT\", count=3)\n",
    "\n",
    "# 문자열 템플릿 결합 (PromptTemplate + PromptTemplate + 문자열)\n",
    "combined_prompt = (\n",
    "              prompt_template\n",
    "              + PromptTemplate.from_template(\"\\n\\n 그리고 {model_name} 모델의 장점을 요약 정리해 주세요\")\n",
    "              + \"\\n\\n {model_name} 모델과 비슷한 AI 모델은 어떤 것이 있나요? 모델명은 {language}로 답변해 주세요.\"\n",
    ")\n",
    "# combined_prompt.format(model_name=\"ChatGPT\", count=3, language=\"영어\")\n",
    "print(combined_prompt)\n",
    "\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "chain = combined_prompt | llm | StrOutputParser()\n",
    "response = chain.invoke({\"model_name\":\"ChatGPT\", \"count\":3, \"language\":\"영어\"})\n",
    "\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PromptTemplate 의 파라미터를 배열 형태로 하여 여러개 사용하는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GPT-4 모델의 학습 원리를 2 문장으로 한국어로 답변해 주세요.', 'Gemma 모델의 학습 원리를 3 문장으로 한국어로 답변해 주세요.', 'Gemini 모델의 학습 원리를 4 문장으로 한국어로 답변해 주세요.', 'Claude 모델의 학습 원리를 5 문장으로 한국어로 답변해 주세요.']\n",
      "<class 'str'> GPT-4 모델의 학습 원리를 2 문장으로 한국어로 답변해 주세요.\n",
      "('GPT‑4는 대량의 텍스트 데이터를 사용해 다음에 올 단어를 예측하도록 스스로 학습하는 자기지도 학습 방식을 적용합니다. 이렇게 얻은 '\n",
      " '파라미터들을 미세조정(fine‑tuning)하거나 인간 피드백을 활용한 강화학습(RLHF)으로 구체적인 작업 수행 능력을 향상시킵니다.')\n",
      "<class 'str'> Gemma 모델의 학습 원리를 3 문장으로 한국어로 답변해 주세요.\n",
      "('Gemma 모델은 대규모 텍스트 데이터를 사전 학습(pre‑training)하여 언어의 통계적 패턴과 의미 관계를 학습합니다. 이후, '\n",
      " '특정 작업에 맞게 소량의 라벨링된 데이터로 미세 조정(fine‑tuning)함으로써 질문 답변, 요약 등 다양한 응용에 최적화됩니다. '\n",
      " '학습 과정에서는 트랜스포머 아키텍처와 자기‑주의(self‑attention) 메커니즘을 활용해 문맥 정보를 효과적으로 통합합니다.')\n",
      "<class 'str'> Gemini 모델의 학습 원리를 4 문장으로 한국어로 답변해 주세요.\n",
      "('Gemini 모델은 대규모 텍스트와 멀티모달 데이터를 사용해 사전 학습(pre‑training) 단계에서 언어와 이미지 등 다양한 입력 '\n",
      " '형태의 패턴을 스스로 발견하도록 훈련됩니다.  \\n'\n",
      " '이후에는 인간 피드백을 활용한 강화 학습(RLHF) 과정을 거쳐, 모델이 생성하는 답변의 정확성·유용성·안전성을 높입니다.  \\n'\n",
      " '학습 과정에서 트랜스포머 기반의 어텐션 메커니즘을 활용해 문맥을 장기적으로 이해하고, 여러 모달 간의 연관성을 효율적으로 '\n",
      " '통합합니다.  \\n'\n",
      " '마지막으로 지속적인 업데이트와 파인튜닝을 통해 최신 지식과 도메인 특화 능력을 꾸준히 향상시킵니다.')\n",
      "<class 'str'> Claude 모델의 학습 원리를 5 문장으로 한국어로 답변해 주세요.\n",
      "('Claude 모델은 대규모 텍스트 데이터를 기반으로 사전 학습(pre‑training)된 트랜스포머 아키텍처를 사용합니다.  \\n'\n",
      " '학습 과정에서는 입력 문장을 토큰화하고, 각 토큰의 다음 토큰을 예측하도록 손실 함수를 최소화합니다.  \\n'\n",
      " '이때 자기지도학습(self‑supervised learning) 기법을 적용해, 별도의 라벨 없이도 문맥 정보를 활용해 모델을 '\n",
      " '최적화합니다.  \\n'\n",
      " '사전 학습이 끝난 뒤에는 특정 작업(예: 질문‑응답, 요약 등)에 맞게 제한된 데이터로 미세 조정(fine‑tuning)하거나 프롬프트 '\n",
      " '엔지니어링을 통해 성능을 조정합니다.  \\n'\n",
      " '결과적으로 Claude는 방대한 언어 패턴을 내부에 저장하고, 새로운 입력에 대해 문맥에 맞는 자연스러운 텍스트를 생성할 수 있게 '\n",
      " '됩니다.')\n"
     ]
    }
   ],
   "source": [
    "template_text = \"{model_name} 모델의 학습 원리를 {count} 문장으로 한국어로 답변해 주세요.\"\n",
    "\n",
    "# PromptTemplate 인스턴스를 생성\n",
    "prompt_template = PromptTemplate.from_template(template_text)\n",
    "\n",
    "questions = [\n",
    "    {\"model_name\": \"GPT-4\", \"count\": 2},\n",
    "    {\"model_name\": \"Gemma\", \"count\": 3},\n",
    "    {\"model_name\": \"Gemini\", \"count\": 4},\n",
    "    {\"model_name\": \"Claude\", \"count\": 5},\n",
    "]\n",
    "\n",
    "# 여러 개의 프롬프트를 미리 생성\n",
    "formatted_prompts = [prompt_template.format(**q) for q in questions]\n",
    "print(formatted_prompts)  # 미리 생성된 질문 목록 확인\n",
    "\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "for prompt in formatted_prompts:\n",
    "    print(type(prompt), prompt)\n",
    "    response = llm.invoke(prompt)\n",
    "    pprint(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2) ChatPromptTemplate\n",
    "* Tuple 형태의 system, user, assistant 메시지 지원\n",
    "* 여러 개의 메시지를 조합하여 LLM에게 전달 가능\n",
    "* 간결성과 가독성이 높고 단순한 구조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='This system is an expert in answering questions about AI. Please provide clear and detailed explanations.', additional_kwargs={}, response_metadata={}), HumanMessage(content='ChatGPT 모델의 학습 원리를 설명해 주세요.', additional_kwargs={}, response_metadata={})]\n",
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "## ChatGPT 모델이 어떻게 학습되는지 (한국어로)  \n",
      "\n",
      "아래에서는 **ChatGPT**(또는 일반적인 대형 언어 모델, LLM)가 학습되는 전 과정을 크게 **세 단계**로 나눠서 설명합니다.\n",
      "\n",
      "---\n",
      "\n",
      "### 1️⃣ 사전 학습 (Pre‑training) – “대량 텍스트를 읽는 단계”\n",
      "\n",
      "| 단계 | 핵심 내용 | 왜 필요한가? |\n",
      "|------|-----------|--------------|\n",
      "| **데이터 수집** | 웹 페이지, 책, 논문, 위키피디아, 뉴스, 포럼 등 수십 ~ 수백 TB 규모의 텍스트를 크롤링·정제합니다. 개인정보·유해 콘텐츠는 필터링하고, 언어·도메인 다양성을 확보합니다. | 모델이 **다양한 상황·주제**에 대해 일반적인 언어 패턴을 배우게 함. |\n",
      "| **토큰화 (Tokenization)** | 텍스트를 **Byte‑Pair Encoding (BPE)** 혹은 **SentencePiece** 같은 서브워드 토크나이저로 변환합니다. 예: “ChatGPT” → `['Chat', '##G', '##PT']`. | 어휘 크기를 적당히 유지하면서 **희소성**을 줄이고, 새로운 단어도 처리 가능하게 함. |\n",
      "| **목표 함수** | **다음 토큰 예측 (Next‑Token Prediction)**, 즉 **자기 회귀 언어 모델링**: \\(\\displaystyle \\max_{\\theta}\\sum_{t} \\log P_\\theta (x_t \\mid x_{<t})\\).<br>모델은 앞선 토큰들을 보고 다음 토큰을 맞추도록 학습합니다. | 텍스트 흐름을 **통계적으로** 이해하고, 문맥‑의존적인 표현을 학습함. |\n",
      "| **아키텍처** | **Transformer Decoder** 기반. 핵심은 **멀티‑헤드 셀프‑어텐션**(Self‑Attention)과 **포지션 워이즈 피드포워드** 레이어. <br>예: GPT‑3은 96개의 레이어, 12 720개의 헤드, 175 B 파라미터. | 셀프‑어텐션은 **전역적인 문맥**을 한 번에 고려하게 해 주어, 긴 문장·문단에서도 의미를 파악할 수 있음. |\n",
      "| **학습 방법** | **분산 학습** (Data Parallel + Model Parallel) → 수천 개 GPU/TPU 클러스터에서 **Mixed‑Precision**(FP16/ BF16)으로 진행.<br>학습 스케줄: **AdamW** 옵티마이저 + **Learning‑Rate Warm‑up → Cosine Decay**. | 대규모 파라미터와 데이터에 대해 **효율적으로** 수렴하도록 함. |\n",
      "\n",
      "> **핵심 포인트**: 사전 학습 단계에서는 **“무언가를 이해한다”**기보다 **“다음에 올 단어를 맞추는 확률 분포를 만든다”**는 것이 목표입니다. 이때 얻어지는 파라미터들은 언어 전반에 대한 **일반적인 지식**을 내포하게 됩니다.\n",
      "\n",
      "---\n",
      "\n",
      "### 2️⃣ 지도 학습 (Supervised Fine‑tuning) – “특정 작업에 맞추는 단계”\n",
      "\n",
      "| 내용 | 설명 |\n",
      "|------|------|\n",
      "| **데이터** | 인간이 만든 **질문‑답변, 대화, 요약, 번역** 등 다양한 형태의 고품질 데이터셋. 예: OpenAI가 만든 *InstructGPT* 데이터, 혹은 공개된 *Alpaca*, *ShareGPT* 등. |\n",
      "| **목표** | **입력 → 기대 출력** 형태로 모델을 학습시켜, “**사용자 지시**에 따라 정확히 행동”하도록 함. <br>예: “‘서울의 인구’를 물으면 정확히 숫자를 말한다.” |\n",
      "| **학습 방식** | 기존 사전‑학습된 가중치를 **초기값**으로 두고, **Cross‑Entropy** 손실을 최소화하는 방식으로 추가 학습. 일반적으로 **학습률**을 사전 학습보다 낮게 설정 (예: 1e‑5 ~ 5e‑5). |\n",
      "| **효과** | 모델이 **“명령을 따르는”** 태도를 갖게 되고, 무작위 텍스트 생성보다 **목표‑지향적인** 응답을 제공. |\n",
      "\n",
      "> **왜 필요한가?**  \n",
      "> 사전 학습만으로는 “다음 토큰을 맞추는” 능력은 뛰어나지만, **“사용자의 의도에 맞게** 답변하거나, **특정 포맷**(예: JSON)으로 출력하는 능력은 부족합니다. 지도 학습은 이런 **실용적인 사용성을** 부여합니다.\n",
      "\n",
      "---\n",
      "\n",
      "### 3️⃣ 강화 학습 (Reinforcement Learning from Human Feedback, RLHF) – “사람이 평가한 보상을 통해 행동을 다듬는다”\n",
      "\n",
      "| 단계 | 설명 |\n",
      "|------|------|\n",
      "| **1) 인간 라벨링** | 인간 평가자(라벨러)가 모델의 여러 응답 후보를 **선호도 순**(예: A > B > C)로 평가합니다. 이때 **‘유해성’, ‘정확성’, ‘친절함’** 등을 기준으로 함. |\n",
      "| **2) 보상 모델 (Reward Model)** | 라벨링 데이터를 바탕으로 **보상 모델**을 학습합니다. 입력(프롬프트+응답) → **스코어**(0~1) 형태로, 높은 스코어일수록 인간이 선호하는 답변. |\n",
      "| **3) PPO (Proximal Policy Optimization) 학습** | 기존 모델을 **정책(policy)** 로 보고, 보상 모델이 주는 보상을 최대화하도록 **PPO** 알고리즘을 적용해 파라미터를 업데이트합니다. <br>핵심: **KL‑다이버전스** 제약을 두어 원래 사전‑학습된 언어 모델과 너무 멀어지지 않게 함. |\n",
      "| **4) 반복** | 새로운 라벨링·보상 모델·PPO 사이클을 여러 번 반복해, 점진적으로 **‘안전하고, 유용하며, 인간 친화적인’** 행동을 학습합니다. |\n",
      "\n",
      "#### RLHF가 제공하는 장점\n",
      "- **안전성**: 유해하거나 편향된 답변을 억제.\n",
      "- **일관성**: 같은 질문에 대해 비슷한 품질의 답변을 제공.\n",
      "- **사용자 맞춤**: “친절하게 설명해 주세요”, “코드 예시를 보여 주세요” 등 구체적인 요구를 더 잘 따름.\n",
      "\n",
      "---\n",
      "\n",
      "## 전체 흐름 요약 (시각화)\n",
      "\n",
      "```\n",
      "1. 대규모 텍스트 수집 → 토큰화 → 사전 학습 (다음 토큰 예측)\n",
      "          |\n",
      "          v\n",
      "2. 고품질 인간 라벨 데이터 → 지도 학습 (명령 수행 능력)\n",
      "          |\n",
      "          v\n",
      "3. 인간 평가 → 보상 모델 → PPO (RLHF) → 안전·유용·친절한 행동\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "## 주요 기술·용어 정리\n",
      "\n",
      "| 용어 | 의미 |\n",
      "|------|------|\n",
      "| **Transformer** | 셀프‑어텐션 기반 신경망 구조. 입력 시퀀스 전체를 동시에 처리해 장기 의존성을 학습. |\n",
      "| **Self‑Attention** | 각 토큰이 다른 모든 토큰과 얼마나 연관되는지를 가중합으로 계산. |\n",
      "| **다중 헤드 (Multi‑Head)** | 여러 개의 어텐션을 병렬로 수행해 다양한 관계를 동시에 학습. |\n",
      "| **Layer Normalization** | 각 레이어의 출력 분포를 정규화해 학습 안정성을 높임. |\n",
      "| **AdamW** | 가중치 감쇠(Weight Decay)를 포함한 Adam 옵티마이저. |\n",
      "| **Mixed‑Precision** | FP16/BF16와 FP32를 섞어 연산해 메모리·시간 효율을 높임. |\n",
      "| **PPO** | 정책 업데이트 시 급격한 변화를 방지하는 강화학습 알고리즘. |\n",
      "| **KL‑다이버전스** | 새 정책과 기존 정책 사이의 차이를 제한해 과도한 망각을 방지. |\n",
      "| **In‑Context Learning** | 별도 파인튜닝 없이, 프롬프트에 예시를 넣어 모델이 **그 예시를 학습**하는 듯한 행동을 보이는 현상. |\n",
      "\n",
      "---\n",
      "\n",
      "## 실제 구현 예시 (간단한 코드 스니펫)\n",
      "\n",
      "아래는 `transformers` 라이브러리를 이용해 **사전 학습된 GPT‑2**를 **지도 학습**하는 매우 간단한 파이프라인 예시입니다.\n",
      "\n",
      "```python\n",
      "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
      "from datasets import load_dataset\n",
      "import torch\n",
      "from torch.utils.data import DataLoader\n",
      "\n",
      "# 1️⃣ 토크나이저와 모델 로드\n",
      "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
      "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
      "model.train()   # fine‑tuning 모드\n",
      "\n",
      "# 2️⃣ 데이터셋 (예: Alpaca 스타일 Q&A)\n",
      "dataset = load_dataset('json', data_files='my_qa_dataset.json')['train']\n",
      "\n",
      "def tokenize_fn(example):\n",
      "    # \"question\" + \"\\nAnswer:\" 형태로 입력을 만든 뒤 토큰화\n",
      "    prompt = f\"Q: {example['question']}\\nA:\"\n",
      "    inputs = tokenizer(prompt, truncation=True, max_length=512)\n",
      "    labels = tokenizer(example['answer'], truncation=True, max_length=512)['input_ids']\n",
      "    inputs['labels'] = labels\n",
      "    return inputs\n",
      "\n",
      "tokenized = dataset.map(tokenize_fn, remove_columns=dataset.column_names)\n",
      "dataloader = DataLoader(tokenized, batch_size=4, shuffle=True)\n",
      "\n",
      "# 3️⃣ 옵티마이저와 학습 루프\n",
      "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
      "\n",
      "for epoch in range(3):\n",
      "    for batch in dataloader:\n",
      "        optimizer.zero_grad()\n",
      "        input_ids = torch.tensor(batch['input_ids']).to('cuda')\n",
      "        attention_mask = torch.tensor(batch['attention_mask']).to('cuda')\n",
      "        labels = torch.tensor(batch['labels']).to('cuda')\n",
      "        outputs = model(input_ids,\n",
      "                        attention_mask=attention_mask,\n",
      "                        labels=labels)\n",
      "        loss = outputs.loss\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        print(f\"epoch {epoch} loss {loss.item():.4f}\")\n",
      "```\n",
      "\n",
      "- 위 코드는 **사전 학습된 모델**을 **질문‑답변 데이터**에 맞춰 **지도 학습**하는 흐름을 보여 줍니다.  \n",
      "- 실제 ChatGPT는 여기서 더 나아가 **RLHF** 단계와 대규모 분산 학습 인프라가 추가됩니다.\n",
      "\n",
      "---\n",
      "\n",
      "## 마무리 – 왜 이런 복잡한 학습 절차가 필요한가?\n",
      "\n",
      "1. **언어 이해와 생성**은 두 가지 큰 목표가 있습니다.  \n",
      "   - *이해*: 텍스트의 통계적 구조와 세계 지식 습득. → **사전 학습**.  \n",
      "   - *생성*: 사용자의 의도에 맞는, 안전하고 유용한 답변 제공. → **지도 학습 + RLHF**.\n",
      "\n",
      "2. **안전·윤리**: 단순히 대규모 텍스트를 학습하면 편향·유해 내용도 그대로 배게 됩니다. 인간 피드백을 통해 **보상 모델**을 만들고, 이를 강화학습에 적용함으로써 위험을 크게 감소시킵니다.\n",
      "\n",
      "3. **범용성**: 사전 학습 단계에서 얻게 되는 **광범위한 언어 지식**은 다양한 downstream 작업(번역, 코딩, 요약 등)에 재활용될 수 있습니다. 따라서 한 번 학습하고 여러 용도로 쓰는 **전이 학습**이 가능해집니다.\n",
      "\n",
      "---\n",
      "\n",
      "### 핵심 정리\n",
      "- **사전 학습**: 대규모 텍스트를 “다음 토큰 예측” 방식으로 학습 → 일반 언어 능력 획득.  \n",
      "- **지도 학습**: 인간이 만든 질문‑답변 등으로 “명령을 따르는” 능력 강화.  \n",
      "- **RLHF**: 인간 평가를 보상으로 변환하고, 강화학습(PPO)으로 모델을 **안전·유용**하게 튜닝.\n",
      "\n",
      "이 과정을 거쳐 최종적으로 **ChatGPT**와 같은 대화형 AI가 **다양한 주제에 대해 자연스럽고, 정확하며, 친절한** 답변을 제공할 수 있게 됩니다. 궁금한 점이 더 있으면 언제든 질문해 주세요!\n"
     ]
    }
   ],
   "source": [
    "# 2-튜플 형태의 메시지 목록으로 프롬프트 생성 (type, content)\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    # role, message\n",
    "    (\"system\", \"This system is an expert in answering questions about {topic}. Please provide clear and detailed explanations.\"),\n",
    "    (\"human\", \"{model_name} 모델의 학습 원리를 설명해 주세요.\"),\n",
    "])\n",
    "\n",
    "messages = chat_prompt.format_messages(topic=\"AI\", model_name=\"ChatGPT\")\n",
    "print(messages)\n",
    "\n",
    "# 생성한 메시지를 바로 주입하여 호출하기\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "print(type(response))\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "## ChatGPT 모델이 어떻게 학습되는지  \n",
      "(한국어로 상세히 설명합니다)\n",
      "\n",
      "---\n",
      "\n",
      "### 1. 전체 흐름 개요\n",
      "1. **데이터 수집 & 전처리** → 2. **토크나이징** → 3. **대규모 사전 학습 (Pre‑training)** → 4. **지도 학습 기반 미세 조정 (Supervised Fine‑tuning)** → 5. **인간 피드백을 활용한 강화 학습 (RLHF)** → 6. **배포 및 추론**  \n",
      "\n",
      "각 단계가 차례대로 모델이 “언어를 이해하고 생성하는 능력”을 점진적으로 키워 줍니다.\n",
      "\n",
      "---\n",
      "\n",
      "## 2. 핵심 기술 – Transformer 아키텍처\n",
      "\n",
      "| 구성 요소 | 역할 | 핵심 아이디어 |\n",
      "|-----------|------|----------------|\n",
      "| **입력 토큰** | 텍스트를 정수 시퀀스로 변환 | Byte‑Pair Encoding (BPE) 혹은 **SentencePiece** 같은 서브워드 토크나이저 사용 |\n",
      "| **임베딩(Embedding)** | 토큰을 고정 차원의 벡터로 매핑 | 학습 가능한 **토큰 임베딩** + **위치 임베딩** (문장 내 순서를 알려 줌) |\n",
      "| **멀티‑헤드 셀프‑어텐션** | 각 토큰이 문맥 전체와 상호작용 | `Q, K, V` 행렬을 만든 뒤 `softmax(QKᵀ / √d)` 로 가중치를 구하고, 이를 `V`와 곱해 새로운 표현을 얻음 |\n",
      "| **피드‑포워드 네트워크(FFN)** | 비선형 변환 | 두 개의 선형 레이어 사이에 `GELU` 같은 활성화 함수 적용 |\n",
      "| **잔차 연결 + 레이어 정규화** | 학습 안정성·깊은 네트워크 학습 가능 | `x + Sublayer(x)` 형태로 스킵 연결 후 `LayerNorm` 적용 |\n",
      "| **스택된 레이어** | 모델 깊이 → 표현력 확대 | GPT‑4 같은 최신 모델은 수백 개 레이어와 수천억 파라미터 보유 |\n",
      "\n",
      "이 구조가 **Causal (autoregressive) Language Model** 로 동작해, **앞의 토큰들만** 보고 다음 토큰을 예측합니다.  \n",
      "\n",
      "---\n",
      "\n",
      "## 3. 단계별 학습 과정\n",
      "\n",
      "### 3.1 데이터 수집 & 전처리\n",
      "- **규모**: 수십 테라바이트 수준의 텍스트 (웹 페이지, 책, 논문, 코드, 대화 로그 등)  \n",
      "- **다양성**: 언어, 도메인, 스타일을 고르게 포함해 일반화 능력 확보  \n",
      "- **클리닝**: 저작권 침해, 개인정보, 불법·유해 콘텐츠 제거 (필터링 + 인간 검토)  \n",
      "- **샘플링**: 데이터가 너무 편중되지 않게 **균형 샘플링**을 적용\n",
      "\n",
      "### 3.2 토크나이징\n",
      "1. **문자 → 서브워드** 변환  \n",
      "   - BPE / SentencePiece 로 **어휘 사전(vocabulary)** 생성 (보통 30k~100k 토큰)  \n",
      "2. **정수 시퀀스** → 모델 입력  \n",
      "   - `\"[Hello, world!]\" → [1542, 23, 987]` 와 같이 정수 인덱스로 변환  \n",
      "\n",
      "### 3.3 대규모 사전 학습 (Pre‑training)\n",
      "- **목표**: **다음 토큰 예측** (Causal LM)  \n",
      "  \\[\n",
      "  \\mathcal{L}_{\\text{CE}} = -\\sum_{t=1}^{T} \\log P_\\theta (x_t \\mid x_{<t})\n",
      "  \\]\n",
      "- **손실 함수**: 토큰‑별 교차 엔트로피 (Cross‑Entropy)  \n",
      "- **최적화 알고리즘**: **AdamW** (weight decay 포함)  \n",
      "- **학습 스케줄**:  \n",
      "  - **Warm‑up** 단계 (learning rate를 점차 올림)  \n",
      "  - **Cosine decay** 혹은 **Linear decay** 로 점차 감소  \n",
      "- **배치 규모**: 수천~수만 시퀀스 (GPU/TPU 클러스터 사용)  \n",
      "- **분산 학습**:  \n",
      "  - **Data Parallelism** (각 GPU에 서로 다른 배치를)  \n",
      "  - **Tensor Parallelism** (한 레이어를 여러 GPU에 나눔)  \n",
      "  - **Pipeline Parallelism** (레이어를 순차적으로 배치)  \n",
      "\n",
      "**왜 사전 학습만으로도 강력한 언어 모델이 되는가?**  \n",
      "- 거대한 텍스트 코퍼스를 통해 **통계적 패턴** (문법, 사실, 상식, 추론 방식 등) 을 학습  \n",
      "- **Self‑attention** 덕분에 긴 문맥(수천 토큰)까지 정보를 연결할 수 있음  \n",
      "\n",
      "### 3.4 지도 학습 기반 미세 조정 (Supervised Fine‑tuning)\n",
      "- **목적**: 특정 작업(예: 질문‑답변, 번역, 코드 생성 등)에 맞게 모델을 조정  \n",
      "- **데이터**: 인간이 만든 **입력‑출력 쌍** (예: “Q: … A: …”)  \n",
      "- **손실**: 사전 학습과 동일하게 **Cross‑Entropy**  \n",
      "- **학습 비율**: 사전 학습보다 **학습률을 낮게** (보통 10‑100배 작게) 설정  \n",
      "\n",
      "### 3.5 인간 피드백을 활용한 강화 학습 (RLHF)\n",
      "1. **수집**: 인간 라벨러가 모델 출력에 **선호도 점수** 혹은 **랭킹**을 부여  \n",
      "2. **보상 모델 (Reward Model)** 훈련  \n",
      "   - 입력: (프롬프트, 모델 출력)  \n",
      "   - 목표: 인간이 선호한 출력에 높은 점수 부여  \n",
      "3. **PPO (Proximal Policy Optimization)** 로 정책(모델) 업데이트  \n",
      "   - **보상** = 보상 모델 점수 − KL‑penalty (원래 사전 학습 정책과의 차이 억제)  \n",
      "   - **목표**: 인간이 선호하는 응답을 더 많이 생성하도록 정책을 미세 조정  \n",
      "\n",
      "RLHF는 **안전성·유용성**을 크게 향상시킵니다. 예를 들어, “불법·유해” 답변을 억제하고, “친절하고 정확한” 답변을 장려합니다.\n",
      "\n",
      "### 3.6 배포와 추론\n",
      "- **양자화(Quantization)**, **프루닝(Pruning)**, **지연 초기화(lazy loading)** 등으로 메모리·속도 최적화  \n",
      "- **샘플링 전략**:  \n",
      "  - **Greedy** (가장 확률 높은 토큰)  \n",
      "  - **Top‑k** / **Top‑p (nucleus)** 샘플링 → 다양성 확보  \n",
      "  - **Temperature** 조절 → 출력 확률 분포 평탄화/날카롭게 조정  \n",
      "- **컨텍스트 길이**: 현재 모델은 수천 토큰까지 기억 (예: GPT‑4‑Turbo는 128k 토큰)  \n",
      "\n",
      "---\n",
      "\n",
      "## 4. 학습 원리를 이해하는 데 도움이 되는 핵심 개념\n",
      "\n",
      "| 개념 | 설명 |\n",
      "|------|------|\n",
      "| **Causal Language Modeling** | “앞에 본 토큰들만 사용해 다음 토큰을 예측” → 순차적 생성 가능 |\n",
      "| **Self‑Attention** | 모든 토큰이 서로를 직접 비교해 가중치를 부여 → 장거리 의존성 학습 |\n",
      "| **Transformer Scaling Laws** | 파라미터 수, 데이터 양, 연산량이 모두 일정 비율로 증가하면 성능이 예측 가능하게 향상 |\n",
      "| **Gradient Descent + AdamW** | 손실을 최소화하기 위해 파라미터를 반복적으로 업데이트 |\n",
      "| **KL‑Penalty in RLHF** | 정책이 사전 학습된 언어 모델에서 너무 멀어지지 않도록 제어 |\n",
      "| **Safety Alignment** | 인간 라벨링·보상 모델·규칙 기반 필터링을 결합해 위험한 출력 억제 |\n",
      "\n",
      "---\n",
      "\n",
      "## 5. 간단히 정리하면\n",
      "\n",
      "1. **대규모 텍스트**를 **토큰화**하고, **Transformer** 기반 모델에 **다음 토큰 예측**이라는 목표로 **수백억 파라미터**를 **수주~수개월** 동안 **분산 학습**한다.  \n",
      "2. 이후 **특정 작업**에 맞게 **지도 학습**으로 미세 조정하고, **인간 피드백**을 보상 신호로 삼아 **RLHF** 단계에서 정책을 다시 최적화한다.  \n",
      "3. 마지막으로 **양자화·프루닝·샘플링** 등을 적용해 실시간 서비스에 적합한 형태로 배포한다.\n",
      "\n",
      "이 전체 과정이 바로 “ChatGPT가 텍스트를 이해하고, 자연스럽게 대화를 이어갈 수 있게 되는” **학습 원리**입니다. 궁금한 부분이 더 있으면 언제든 질문해 주세요!\n"
     ]
    }
   ],
   "source": [
    "# 체인을 생성하여 호출하기\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "chain = chat_prompt | llm | StrOutputParser()\n",
    "\n",
    "response = chain.invoke({\"topic\":\"AI\", \"model_name\":\"ChatGPT\"})\n",
    "print(type(response))\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) ChatPromptTemplate\n",
    "* SystemMessagePromptTemplate와 HumanMessagePromptTemplate 클래스 사용\n",
    "* 객체 지향적 접근 - Message 객체를 독립적으로 생성 가능\n",
    "* 여러 조건에 따라 다른 시스템 메시지 선택\n",
    "\n",
    "```python\n",
    "if user_is_beginner:\n",
    "    system_message = SystemMessagePromptTemplate.from_template(\"초보자를 위한 설명: {topic}\")\n",
    "else:\n",
    "    system_message = SystemMessagePromptTemplate.from_template(\"전문가를 위한 상세 분석: {topic}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Deep Learning – A Clear, Detailed Overview\n",
      "\n",
      "### 1. What is deep learning?\n",
      "Deep learning is a **subfield of machine learning** that models high‑level abstractions in data by using **artificial neural networks with many (deep) layers**.  \n",
      "In simple terms, it’s a way for computers to automatically learn useful representations—from raw input (like pixels, audio waveforms, or text) all the way up to complex concepts (objects, speech, language meaning)—without the need for handcrafted features.\n",
      "\n",
      "| Aspect | Traditional Machine Learning | Deep Learning |\n",
      "|--------|------------------------------|---------------|\n",
      "| **Feature engineering** | Manual, domain‑specific | Learned automatically by the network |\n",
      "| **Model complexity** | Shallow (e.g., linear models, decision trees) | Very deep (tens to thousands of layers) |\n",
      "| **Data requirement** | Works with relatively small datasets | Thrives on massive datasets |\n",
      "| **Performance** | Good for structured/tabular data | State‑of‑the‑art on images, speech, text, video |\n",
      "\n",
      "---\n",
      "\n",
      "### 2. Core Building Block – The Artificial Neuron\n",
      "\n",
      "A **neuron (or node)** computes a weighted sum of its inputs, adds a bias, and passes the result through a non‑linear activation function:\n",
      "\n",
      "\\[\n",
      "a = \\sigma\\bigl(\\mathbf{w}^\\top \\mathbf{x} + b\\bigr)\n",
      "\\]\n",
      "\n",
      "* **\\( \\mathbf{x} \\)** – input vector (outputs of previous layer or raw data)  \n",
      "* **\\( \\mathbf{w} \\)** – learnable weights  \n",
      "* **\\( b \\)** – learnable bias  \n",
      "* **\\( \\sigma(\\cdot) \\)** – activation (e.g., ReLU, sigmoid, tanh)\n",
      "\n",
      "A **layer** is a collection of such neurons that operate in parallel. Stacking layers yields a **deep neural network**.\n",
      "\n",
      "---\n",
      "\n",
      "### 3. Typical Architectures (Why “deep”?)\n",
      "\n",
      "| Architecture | Typical Use‑Case | Key Idea |\n",
      "|--------------|------------------|----------|\n",
      "| **Fully‑Connected (Dense) Networks** | Tabular data, small‑scale classification | Every neuron connects to all neurons in the next layer |\n",
      "| **Convolutional Neural Networks (CNNs)** | Images, video, spatial data | Learn local patterns via convolution kernels; weight sharing reduces parameters |\n",
      "| **Recurrent Neural Networks (RNNs) & Variants (LSTM, GRU)** | Sequential data (text, speech, time series) | Maintain a hidden state that evolves over time |\n",
      "| **Transformers** | Language, vision, multimodal tasks | Use self‑attention to relate all positions in a sequence; highly parallelizable |\n",
      "| **Autoencoders / Variational Autoencoders (VAEs)** | Dimensionality reduction, generative modeling | Learn to reconstruct input; latent space captures compressed representation |\n",
      "| **Generative Adversarial Networks (GANs)** | Image synthesis, style transfer | Two networks (generator & discriminator) compete, yielding realistic outputs |\n",
      "\n",
      "---\n",
      "\n",
      "### 4. How a Deep Network Learns – Training Process\n",
      "\n",
      "1. **Forward Pass**  \n",
      "   Input data flows through the network, producing predictions \\( \\hat{y} \\).\n",
      "\n",
      "2. **Loss Computation**  \n",
      "   A scalar loss \\( \\mathcal{L}( \\hat{y}, y ) \\) quantifies the error (e.g., cross‑entropy for classification, MSE for regression).\n",
      "\n",
      "3. **Backward Pass (Back‑Propagation)**  \n",
      "   Using the chain rule, gradients of the loss w.r.t. every weight \\( \\frac{\\partial \\mathcal{L}}{\\partial w} \\) are computed.\n",
      "\n",
      "4. **Parameter Update**  \n",
      "   An optimizer (SGD, Adam, RMSprop, etc.) updates the weights:  \n",
      "   \\[\n",
      "   w \\leftarrow w - \\eta \\, \\frac{\\partial \\mathcal{L}}{\\partial w}\n",
      "   \\]  \n",
      "   where \\( \\eta \\) is the learning rate.\n",
      "\n",
      "5. **Iterate**  \n",
      "   Repeat over many **epochs** (full passes through the training set) until loss converges or performance plateaus.\n",
      "\n",
      "**Regularization tricks** (dropout, weight decay, batch normalization, data augmentation) help prevent over‑fitting and improve generalization.\n",
      "\n",
      "---\n",
      "\n",
      "### 5. Why Deep Learning Works So Well\n",
      "\n",
      "| Reason | Explanation |\n",
      "|--------|-------------|\n",
      "| **Hierarchical Feature Learning** | Early layers capture low‑level patterns (edges, tones); deeper layers combine them into high‑level concepts (objects, semantics). |\n",
      "| **Large‑Scale Data & Compute** | Modern GPUs/TPUs and massive labeled datasets (e.g., ImageNet) enable training of millions‑of‑parameter models. |\n",
      "| **End‑to‑End Optimization** | The same objective function drives every layer, ensuring that learned features are directly useful for the final task. |\n",
      "| **Expressive Power** | Deep networks can approximate highly complex functions; universal approximation theorems guarantee they can represent any continuous mapping given enough width/depth. |\n",
      "\n",
      "---\n",
      "\n",
      "### 6. Real‑World Applications\n",
      "\n",
      "| Domain | Example |\n",
      "|--------|---------|\n",
      "| **Computer Vision** | Image classification (ResNet, EfficientNet), object detection (YOLO, Faster‑RCNN), medical imaging analysis |\n",
      "| **Natural Language Processing** | Machine translation (Transformer), sentiment analysis (BERT, RoBERTa), chatbots (ChatGPT) |\n",
      "| **Speech & Audio** | Speech‑to‑text (DeepSpeech, wav2vec), music generation (OpenAI Jukebox) |\n",
      "| **Robotics & Control** | Vision‑guided manipulation, reinforcement‑learning agents (AlphaGo, DQN) |\n",
      "| **Healthcare** | Drug discovery (graph neural networks), disease prediction from electronic health records |\n",
      "| **Finance** | Fraud detection, algorithmic trading, risk modeling |\n",
      "| **Creative AI** | Image synthesis (Stable Diffusion, DALL·E), video generation, style transfer |\n",
      "\n",
      "---\n",
      "\n",
      "### 7. Common Challenges & Limitations\n",
      "\n",
      "| Challenge | Mitigation Strategies |\n",
      "|-----------|-----------------------|\n",
      "| **Data Hunger** | Transfer learning, data augmentation, synthetic data generation |\n",
      "| **Compute Cost** | Model pruning, quantization, knowledge distillation, efficient architectures (MobileNet, EfficientNet) |\n",
      "| **Interpretability** | Saliency maps, SHAP, LIME, concept activation vectors |\n",
      "| **Robustness & Safety** | Adversarial training, certified defenses, rigorous testing pipelines |\n",
      "| **Bias & Fairness** | Curated datasets, bias audits, fairness‑aware loss functions |\n",
      "| **Catastrophic Forgetting (in continual learning)** | Elastic weight consolidation, replay buffers, modular architectures |\n",
      "\n",
      "---\n",
      "\n",
      "### 8. Getting Started – A Minimal Example (Python + PyTorch)\n",
      "\n",
      "```python\n",
      "import torch\n",
      "import torch.nn as nn\n",
      "import torch.optim as optim\n",
      "from torchvision import datasets, transforms\n",
      "\n",
      "# 1️⃣ Define a simple CNN\n",
      "class SimpleCNN(nn.Module):\n",
      "    def __init__(self):\n",
      "        super().__init__()\n",
      "        self.conv = nn.Sequential(\n",
      "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),  # 28×28 → 28×28\n",
      "            nn.ReLU(),\n",
      "            nn.MaxPool2d(2)                                         # 28×28 → 14×14\n",
      "        )\n",
      "        self.fc = nn.Sequential(\n",
      "            nn.Flatten(),\n",
      "            nn.Linear(32 * 14 * 14, 128),\n",
      "            nn.ReLU(),\n",
      "            nn.Linear(128, 10)   # 10 classes (MNIST)\n",
      "        )\n",
      "\n",
      "    def forward(self, x):\n",
      "        return self.fc(self.conv(x))\n",
      "\n",
      "# 2️⃣ Load data\n",
      "transform = transforms.Compose([transforms.ToTensor()])\n",
      "train_set = datasets.MNIST(root='.', train=True, download=True, transform=transform)\n",
      "train_loader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True)\n",
      "\n",
      "# 3️⃣ Instantiate model, loss, optimizer\n",
      "model = SimpleCNN()\n",
      "criterion = nn.CrossEntropyLoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
      "\n",
      "# 4️⃣ Training loop (1 epoch for illustration)\n",
      "model.train()\n",
      "for images, labels in train_loader:\n",
      "    optimizer.zero_grad()\n",
      "    outputs = model(images)\n",
      "    loss = criterion(outputs, labels)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "\n",
      "print(\"Training step completed.\")\n",
      "```\n",
      "\n",
      "*This snippet shows the whole pipeline: model definition, data loading, loss computation, back‑propagation, and parameter update.*\n",
      "\n",
      "---\n",
      "\n",
      "### 9. Where the Field Is Heading (2024‑2025)\n",
      "\n",
      "| Trend | What It Means |\n",
      "|-------|---------------|\n",
      "| **Foundation Models** | Extremely large, pre‑trained networks (e.g., GPT‑4, CLIP, DALL·E 3) that can be adapted to many downstream tasks with few examples. |\n",
      "| **Multimodal Learning** | Jointly processing text, images, audio, and even video to achieve richer understanding (e.g., Flamingo, Gemini). |\n",
      "| **Efficient & Tiny Models** | Techniques like **Sparse Transformers**, **Mixture‑of‑Experts**, and **Neural Architecture Search** produce models that run on phones or edge devices. |\n",
      "| **Neuro‑Symbolic Integration** | Combining deep learning’s pattern recognition with symbolic reasoning for better logical consistency. |\n",
      "| **Responsible AI** | Built‑in safeguards for bias detection, explainability, and safe deployment are becoming standard parts of the training pipeline. |\n",
      "\n",
      "---\n",
      "\n",
      "## TL;DR\n",
      "\n",
      "- **Deep learning** = neural networks with many layers that automatically learn hierarchical features from raw data.  \n",
      "- It works by **forward propagation → loss → back‑propagation → gradient‑based updates**.  \n",
      "- **CNNs**, **RNNs**, **Transformers**, **GANs**, etc., are specialized deep architectures for different data types.  \n",
      "- The approach excels when you have **large datasets** and **substantial compute**, delivering state‑of‑the‑art performance in vision, language, speech, and many other domains.  \n",
      "- Challenges (data, compute, interpretability, bias) are active research areas, and the community is rapidly developing tools to address them.\n",
      "\n",
      "Feel free to ask if you’d like to dive deeper into any specific architecture, training technique, or application!\n"
     ]
    }
   ],
   "source": [
    "# ChatMessagePromptTemplate 활용\n",
    "\n",
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    ChatMessagePromptTemplate\n",
    ")\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 개별 메시지 템플릿 정의\n",
    "system_message = SystemMessagePromptTemplate.from_template(\n",
    "    \"You are an AI expert in {topic}. Please provide clear and detailed explanations.\"\n",
    ")\n",
    "user_message = HumanMessagePromptTemplate.from_template(\n",
    "    \"{question}\"\n",
    ")\n",
    "ai_message = AIMessagePromptTemplate.from_template(\n",
    "    \"This is an example answer about {topic}.\"\n",
    ")\n",
    "\n",
    "# ChatPromptTemplate로 메시지들을 묶기\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    system_message,\n",
    "    user_message,\n",
    "    ai_message\n",
    "])\n",
    "\n",
    "# 메시지 생성\n",
    "messages = chat_prompt.format_messages(topic=\"AI\", question=\"What is deep learning?\")\n",
    "\n",
    "# LLM 호출\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "# 결과 출력\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ChatMessagePromptTemplate는 여러 종류의 메시지(시스템, 인간, AI)를 조합하여 복잡한 프롬프트를 생성할 때 유용합니다.\n",
    "* SystemMessagePromptTemplate: 이 템플릿은 AI 모델에게 역할을 부여하거나 전반적인 규칙을 설정하는 시스템 메시지를 만듭니다. 위의 예시에서는 \"번역을 도와주는 유용한 도우미\"라는 역할을 지정합니다.\n",
    "* HumanMessagePromptTemplate: 이 템플릿은 사용자의 질문이나 요청을 담는 인간 메시지를 만듭니다. 아래의 예시에서는 번역할 텍스트를 입력받습니다.\n",
    "* ChatPromptTemplate.from_messages: 이 클래스 메서드는 시스템 메시지, 인간 메시지 등 여러 종류의 MessagePromptTemplate 객체들을 리스트로 받아 하나의 채팅 프롬프트 템플릿으로 통합합니다.\n",
    "* format_messages: 이 메서드는 정의된 템플릿에 실제 값을 채워 넣어 [SystemMessage, HumanMessage] 형태의 리스트를 반환합니다. 이 리스트는 채팅 모델(Chat Model) 에 바로 전달될 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='You are a helpful assistant that translates English to Korean.', additional_kwargs={}, response_metadata={}), HumanMessage(content='I love programming.', additional_kwargs={}, response_metadata={})]\n",
      "나는 프로그래밍을 사랑합니다.\n"
     ]
    }
   ],
   "source": [
    "# 필요한 라이브러리 임포트\n",
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "# 1. SystemMessagePromptTemplate와 HumanMessagePromptTemplate 생성\n",
    "# SystemMessagePromptTemplate는 모델의 페르소나 또는 기본 지침을 설정합니다.\n",
    "system_template = \"You are a helpful assistant that translates {input_language} to {output_language}.\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
    "\n",
    "# HumanMessagePromptTemplate는 사용자로부터 받는 입력 프롬프트를 정의합니다.\n",
    "human_template = \"{text_to_translate}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "# 2. ChatPromptTemplate 생성\n",
    "# 위에서 만든 두 템플릿을 리스트로 묶어 ChatPromptTemplate을 만듭니다.\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "\n",
    "# 3. 프롬프트 포맷팅\n",
    "# chat_prompt_template.format_messages()를 사용하여 최종 메시지 리스트를 생성합니다.\n",
    "# 이 함수는 딕셔너리 형태의 입력 변수를 받습니다.\n",
    "formatted_prompt = chat_prompt_template.format_messages(\n",
    "    input_language=\"English\",\n",
    "    output_language=\"Korean\",\n",
    "    text_to_translate=\"I love programming.\"\n",
    ")\n",
    "\n",
    "# 4. 결과 출력\n",
    "print(formatted_prompt)\n",
    "\n",
    "# LLM 호출\n",
    "response = llm.invoke(formatted_prompt)\n",
    "\n",
    "# 결과 출력\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4) FewShotPromptTemplate\n",
    "* FewShotPromptTemplate은 모델이 특정 형식을 따르게 하거나, 일관된 응답을 생성하도록 유도할 때 유용합니다.\n",
    "* 도메인 지식이 필요하거나, AI가 오답을 줄이고 더 신뢰할 만한 답변을 생성하도록 해야 할 때 효과적입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4-1) PromptTemplate을 사용하지 않는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "태양계에는 8개의 행성이 있습니다. \n",
      "\n",
      "1.  수성: 태양과 가장 가까운 행성으로, 표면이 암석으로 구성되어 있고 극도로 높은 온도와 낮은 온도가 반복됩니다.\n",
      "2.  금성: 태양계에서 두 번째로 가까운 행성으로, 두꺼운 대기로 인해 극심한 온실 효과가 발생하여 매우 뜨겁습니다.\n",
      "3.  지구: 우리가 사는 행성으로, 물과 대기가 있어 생명체가 존재할 수 있습니다.\n",
      "4.  화성: 태양계에서 네 번째로 가까운 행성으로, 붉은색의 모래사막으로 덮여 있고 물과 생명체의 존재 가능성이 있습니다.\n",
      "5.  목성: 태양계에서 가장 큰 행성으로, 가스 거인이며 강력한 자기장과 수많은 위성을 가지고 있습니다.\n",
      "6.  토성: 태양계에서 두 번째로 큰 행성으로, 가스 거인이며 아름다운 고리를 가지고 있습니다.\n",
      "7.  천왕성: 태양계에서 일곱 번째로 가까운 행성으로, 가스 거인이며 자전축이 기울어져 있어 극단적인 기후 변화를 경험합니다.\n",
      "8.  해왕성: 태양계에서 가장 먼 행성으로, 가스 거인이며 강한 바람과 극적인 기후 변화를 가지고 있습니다.\n",
      "\n",
      "이러한 행성들은 각각 고유한 특징과 성질을 가지고 있으며, 태양계에서 중요한 역할을 합니다.\n"
     ]
    }
   ],
   "source": [
    "# PromptTemplate을 사용하지 않는 경우\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# model\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "# chain 실행\n",
    "result = llm.invoke(\"태양계의 행성들을 간략히 정리해 주세요.\")\n",
    "\n",
    "print(type(result))\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4-2) FewShotChatMessagePromptTemplate 사용하는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first=ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='당신은 초등학생도 쉽게 이해할 수 있도록 쉽게 설명하는 과학 교육자입니다.'), additional_kwargs={}), FewShotChatMessagePromptTemplate(examples=[{'input': '뉴턴의 운동 법칙을 요약해 주세요.', 'output': '### 뉴턴의 운동 법칙\\n1. **관성의 법칙**: 힘이 작용하지 않으면 물체는 계속 같은 상태를 유지합니다.\\n2. **가속도의 법칙**: 물체에 힘이 작용하면, 힘과 질량에 따라 가속도가 결정됩니다.\\n3. **작용-반작용 법칙**: 모든 힘에는 크기가 같고 방향이 반대인 힘이 작용합니다.'}, {'input': '지구의 대기 구성 요소를 알려주세요.', 'output': '### 지구 대기의 구성\\n- **질소 (78%)**: 대기의 대부분을 차지합니다.\\n- **산소 (21%)**: 생명체가 호흡하는 데 필요합니다.\\n- **아르곤 (0.93%)**: 반응성이 낮은 기체입니다.\\n- **이산화탄소 (0.04%)**: 광합성 및 온실 효과에 중요한 역할을 합니다.'}], input_variables=[], input_types={}, partial_variables={}, example_prompt=ChatPromptTemplate(input_variables=['input', 'output'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=['output'], input_types={}, partial_variables={}, template='{output}'), additional_kwargs={})])), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})]) middle=[] last=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x107ec4fc0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x107ec5a70>, root_client=<openai.OpenAI object at 0x107ec50f0>, root_async_client=<openai.AsyncOpenAI object at 0x107ec55b0>, model_name='meta-llama/llama-4-scout-17b-16e-instruct', temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://api.groq.com/openai/v1')\n",
      "### 양자 컴퓨터\n",
      "#### 정의\n",
      "- **양자 컴퓨터**: 양자역학의 원리를 이용해 정보를 처리하는 컴퓨터입니다.\n",
      "\n",
      "#### 특징\n",
      "- **큐비트**: 0과 1을 동시에 표현할 수 있는 양자 단위입니다.\n",
      "- **병렬 처리**: 많은 정보를 동시에 처리할 수 있습니다.\n",
      "- **초고속 연산**: 기존 컴퓨터보다 빠르게 복잡한 문제를 해결할 수 있습니다.\n",
      "\n",
      "#### 활용 분야\n",
      "- **암호학**: 보안 강화\n",
      "- **물리학 및 화학**: 복잡한 분자 시뮬레이션\n",
      "- **최적화 문제**: 복잡한 문제를 빠르게 해결\n",
      "\n",
      "#### 현재 상황\n",
      "- 아직 초기 단계이며, 기술적 도전이 많습니다. 하지만, 미래의 기술 발전에 큰 기대가 있습니다.\n"
     ]
    }
   ],
   "source": [
    "# FewShotChatMessagePromptTemplate 사용하는 경우\n",
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"input\": \"뉴턴의 운동 법칙을 요약해 주세요.\",\n",
    "        \"output\": \"\"\"### 뉴턴의 운동 법칙\n",
    "1. **관성의 법칙**: 힘이 작용하지 않으면 물체는 계속 같은 상태를 유지합니다.\n",
    "2. **가속도의 법칙**: 물체에 힘이 작용하면, 힘과 질량에 따라 가속도가 결정됩니다.\n",
    "3. **작용-반작용 법칙**: 모든 힘에는 크기가 같고 방향이 반대인 힘이 작용합니다.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"지구의 대기 구성 요소를 알려주세요.\",\n",
    "        \"output\": \"\"\"### 지구 대기의 구성\n",
    "- **질소 (78%)**: 대기의 대부분을 차지합니다.\n",
    "- **산소 (21%)**: 생명체가 호흡하는 데 필요합니다.\n",
    "- **아르곤 (0.93%)**: 반응성이 낮은 기체입니다.\n",
    "- **이산화탄소 (0.04%)**: 광합성 및 온실 효과에 중요한 역할을 합니다.\"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# 예제 프롬프트 템플릿\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"ai\", \"{output}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# FewShotChatMessagePromptTemplate 적용\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "\n",
    "# 최종 프롬프트 구성\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"당신은 초등학생도 쉽게 이해할 수 있도록 쉽게 설명하는 과학 교육자입니다.\"),\n",
    "        few_shot_prompt,\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 모델 생성 및 체인 구성\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.0)\n",
    "chain = final_prompt | llm\n",
    "print(chain)\n",
    "\n",
    "# 테스트 실행\n",
    "# result = chain.invoke({\"input\": \"태양계의 행성들을 간략히 정리해 주세요.\"})\n",
    "result = chain.invoke({\"input\": \"양자컴퓨터 정리해 주세요.\"})\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5-1) PartialPrompt \n",
    "* 프롬프트를 더 동적으로 활용할 수 있으며, AI 응답을 더 일관성 있게 조정 가능함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 프롬프트: 가을에 일어나는 대표적인 지구과학 현상은 태풍 발생이 맞나요? 가을에 주로 발생하는 지구과학 현상을 3개 알려주세요\n",
      " 모델 응답: ### 가을에 주로 나타나는 대표적인 지구과학 현상\n",
      "\n",
      "| # | 현상 | 주요 특징 및 발생 메커니즘 | 가을에 두드러지는 이유 |\n",
      "|---|------|---------------------------|------------------------|\n",
      "| 1 | **태풍(열대 저기압) 발생·접근** | • 바다 표면 온도가 ≥ 26 °C 인 열대·아열대 해역에서 발달 <br>• 중심 저기압이 강화되면서 강풍·폭우를 동반 <br>• 이동 경로는 대기 중 고기압·저기압 배치에 크게 좌우 | • 8‑10월은 남서·동남아시아·서태평양 해수면 온도가 가장 높아 ‘태풍 최빈기’가 됩니다.<br>• 동아시아(한반도·중국·일본 등)에서는 태풍이 북상하면서 가을에 가장 많이 영향을 미칩니다. |\n",
      "| 2 | **한랭전선(Cold Front) 통과와 급격한 기온·습도 변화** | • 남쪽에서 온난·습한 공기가 북쪽에서 차가운 대륙성 공기와 만나면서 형성 <br>• 전선이 통과하면 기온이 급락하고, 바람은 남동·남서 → 북동·북서 방향으로 바뀝니다.<br>• 전선 앞뒤로 구름·비·때로는 눈까지 동반 | • 여름이 끝나면서 북극·시베리아 고기압이 강화되고, 남쪽의 온난 해양 기단이 약화됩니다.<br>• 이때 한랭전선이 남하해 한반도·동아시아에 자주 도달해 ‘가을 기온 급락’ 현상을 일으킵니다. |\n",
      "| 3 | **가을철 집중호우·홍수·산사태 위험 증가** | • 태풍·전선이 동반하는 폭우가 짧은 시간에 대량 강수 <br>• 산악 지역에서는 급경사면에 물이 급히 모여 **산사태·흙사태**를 유발 <br>• 저지대·하천 주변에서는 급격한 수위 상승으로 **홍수** 위험이 커짐 | • 가을은 태풍·전선이 동시에 작용하는 시기라 강우 강도가 높아집니다.<br>• 토양이 여름 동안 이미 포화 상태에 가까워 있어 배수가 어려워지고, 그 결과 산사태·홍수 위험이 크게 늘어납니다. |\n",
      "\n",
      "---\n",
      "\n",
      "## 1️⃣ “태풍이 가을의 대표 현상”이라는 말, 맞을까?\n",
      "\n",
      "- **맞습니다**. 특히 동아시아·동북아시아(한반도, 일본, 중국 동부)에서는 **8월 말부터 10월까지**가 태풍이 가장 많이 발생·접근하는 시기입니다.  \n",
      "- 태풍은 **대기·해양·지표면**이 모두 연관된 복합 지구과학 현상이므로, 가을철 기후·재해를 논할 때 가장 핵심적인 현상이라고 할 수 있습니다.  \n",
      "\n",
      "하지만 가을에는 **태풍 외에도** 위 표에 제시한 한랭전선 통과와 그에 따른 급격한 기온·풍향 변화, 그리고 **집중호우·홍수·산사태**와 같은 현상도 매우 흔하게 나타납니다. 따라서 “가을의 대표 현상”을 하나만 꼽기보다는 **다양한 대기·수문·지형 현상이 복합적으로 작용**한다는 점을 기억하는 것이 좋습니다.\n",
      "\n",
      "---\n",
      "\n",
      "## 간단 요약\n",
      "\n",
      "| 현상 | 가을에 두드러지는 이유 |\n",
      "|------|------------------------|\n",
      "| **태풍** | 해수면 온도·대기 흐름이 최적화돼 북상·접근이 빈번 |\n",
      "| **한랭전선 통과** | 북극·시베리아 고기압 강화 → 차가운 대륙성 공기가 남하 |\n",
      "| **집중호우·홍수·산사태** | 태풍·전선 동시 작용 + 토양 포화 → 급격한 강우와 물 흐름 |\n",
      "\n",
      "이 세 가지 현상이 가을에 가장 흔히 관측되는 **지구과학적 현상**이며, 각각이 서로 연계돼 기상·수문·지형 재해를 동시에 야기할 수 있다는 점을 유념하시기 바랍니다. 🌦️🏔️🌊\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 계절을 결정하는 함수 (남반구/북반구 고려)\n",
    "def get_current_season(hemisphere=\"north\"):\n",
    "    month = datetime.now().month\n",
    "\n",
    "    if hemisphere == \"north\":  # 북반구 (기본값)\n",
    "        if 3 <= month <= 5:\n",
    "            return \"봄\"\n",
    "        elif 6 <= month <= 8:\n",
    "            return \"여름\"\n",
    "        elif 9 <= month <= 11:\n",
    "            return \"가을\"\n",
    "        else:\n",
    "            return \"겨울\"\n",
    "    else:  # 남반구 (계절 반대)\n",
    "        if 3 <= month <= 5:\n",
    "            return \"가을\"\n",
    "        elif 6 <= month <= 8:\n",
    "            return \"겨울\"\n",
    "        elif 9 <= month <= 11:\n",
    "            return \"봄\"\n",
    "        else:\n",
    "            return \"여름\"\n",
    "\n",
    "# 프롬프트 템플릿 정의 (부분 변수 적용)\n",
    "prompt = PromptTemplate(\n",
    "    template=\"{season}에 일어나는 대표적인 지구과학 현상은 {phenomenon}이 맞나요? {season}에 주로 발생하는 지구과학 현상을 3개 알려주세요\",\n",
    "    input_variables=[\"phenomenon\"],  # 사용자 입력 필요\n",
    "    partial_variables={\"season\": get_current_season()}  # 동적으로 계절 값 할당\n",
    ")\n",
    "\n",
    "# OpenAI 모델 초기화\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.0)\n",
    "\n",
    "# 특정 계절의 현상 질의\n",
    "query = prompt.format(phenomenon=\"태풍 발생\")\n",
    "result = llm.invoke(query)\n",
    "\n",
    "\n",
    "# 결과 출력\n",
    "print(f\" 프롬프트: {query}\")\n",
    "print(f\" 모델 응답: {result.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 계절: 봄\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 계절을 결정하는 함수 (남반구/북반구 고려)\n",
    "def get_current_season(hemisphere=\"north\"):\n",
    "    month = datetime.now().month\n",
    "\n",
    "    if hemisphere == \"north\":  # 북반구 (기본값)\n",
    "        if 3 <= month <= 5:\n",
    "            return \"봄\"\n",
    "        elif 6 <= month <= 8:\n",
    "            return \"여름\"\n",
    "        elif 9 <= month <= 11:\n",
    "            return \"가을\"\n",
    "        else:\n",
    "            return \"겨울\"\n",
    "    else:  # 남반구 (계절 반대)\n",
    "        if 3 <= month <= 5:\n",
    "            return \"가을\"\n",
    "        elif 6 <= month <= 8:\n",
    "            return \"겨울\"\n",
    "        elif 9 <= month <= 11:\n",
    "            return \"봄\"\n",
    "        else:\n",
    "            return \"여름\"\n",
    "\n",
    "# Step 1: 현재 계절 결정\n",
    "season_name = get_current_season(\"south\")  # 계절 값 얻기\n",
    "print(f\"현재 계절: {season_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 봄에 발생하는 자연 현상:\n",
      "봄에 자주 발생하는 대표적인 지구과학 현상은 다음과 같습니다.\n",
      "\n",
      "1.  **춘분**: 매년 3월 20일 또는 21일 경에 발생하는 춘분은 낮과 밤의 길이가 거의 같아지는 날입니다. 이는 지구의 축이 태양의 중심을 통과하는 날로, 지구상의 모든 지역에서 낮과 밤의 길이가 거의 같아집니다.\n",
      "\n",
      "2.  **황사**: 황사는 중국 북서지방의 사막이나 황화지대에서 강한 바람에 의해 일어나는 사막 먼지입니다. 이 현상은 특히 봄철에 자주 발생합니다.\n",
      "\n",
      "3.  **번개**: 봄철에는 날씨 변화가 심해 번개가 자주 발생합니다. 봄은 대기가 불안정해지면서 상승 기류가 강해지고, 구름이 형성되어 번개가 발생하기 쉽습니다.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 2: 해당 계절의 자연 현상 추천\n",
    "prompt2 = ChatPromptTemplate.from_template(\n",
    "    \"{season}에 주로 발생하는 대표적인 지구과학 현상 3가지를 알려주세요. \"\n",
    "    \"각 현상에 대해 간단한 설명을 포함해주세요.\"\n",
    ")\n",
    "\n",
    "# # OpenAI 모델 사용\n",
    "# #llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.0)\n",
    "# llm = ChatOpenAI(\n",
    "#     #api_key=OPENAI_API_KEY,\n",
    "#     base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "#     model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "#     temperature=0.0\n",
    "# )\n",
    "\n",
    "# 체인 2: 자연 현상 추천 (입력: 계절 → 출력: 자연 현상 목록)\n",
    "chain2 = (\n",
    "    {\"season\": lambda x : season_name}  # chain1의 출력을 season 변수로 전달\n",
    "    | prompt2\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 실행: 현재 계절에 따른 자연 현상 추천\n",
    "response = chain2.invoke({})\n",
    "print(f\"\\n {season_name}에 발생하는 자연 현상:\\n{response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5-2) PartialPrompt \n",
    "* API 호출 데이터, 시간 정보, 사용자 정보 등을 반영할 때 매우 유용함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 프롬프트: 현재 1달러 = 1377.98원 기준으로 환율 정보를 알려드립니다. 이에 대한 분석을 제공해 주세요.\n",
      " 모델 응답: ## 최근 원/달러 환율 동향 \n",
      "\n",
      "원/달러 환율은 2023년 1377.98원(2023년 10월 6일 16시 기준)을 기록하고 있습니다. 이는 최근 글로벌 경제의 불확실성과 미국의 통화정책 등 여러 가지 요인에 의해 영향을 받고 있습니다. \n",
      "\n",
      "### 주요 요인\n",
      "\n",
      "*   **미국 경제와 통화 정책**: 미국 경제가 견조한 성장세를 보이고, 인플레이션이 높은 수준을 유지함에 따라 연방준비제도(Fed)는 금리 인상 기조를 유지하고 있습니다. \n",
      "*   **글로벌 경제 불확실성**: 글로벌 경제의 불확실성이 지속되며 안전자산 선호도가 높아지고 있습니다. 특히, 주요국들의 경제 성장 둔화와 지정학적 리스크가 원/달러 환율에 영향을 미치고 있습니다. \n",
      "*   **원유 가격**: 국제 유가의 변동도 원/달러 환율에 영향을 주는 요인 중 하나입니다. 유가 상승 시, 경상수지 악화 우려로 인해 원화 가치가 하락할 수 있습니다. \n",
      "\n",
      "### 전망 \n",
      "\n",
      "원/달러 환율의 전망은 다양한 변수에 따라 달라질 수 있습니다. Fed의 추가 금리 인상 여부, 글로벌 경제의 회복 속도, 지정학적 이슈 등 여러 요인들이 복합적으로 작용할 것으로 예상됩니다. \n",
      "\n",
      "현재로서는 원/달러 환율이 1,350원대 후반에서 등락할 가능성이 있지만, 향후 경제 지표 발표와 글로벌 경제 상황 변화에 따라 변동성이 확대될 수 있습니다. \n",
      "\n",
      "### 투자 전략 \n",
      "\n",
      "*   **환율 변동 위험 관리**: 수출입 기업들은 환율 변동에 따른 위험을 관리하기 위해 환헤지 상품을 활용할 수 있습니다. \n",
      "*   **다양한 자산 투자**: 투자자들은 원화 자산과 외화 자산에 분산 투자하여 환율 변동 위험을 줄일 수 있습니다. \n",
      "*   **경제 지표 주목**: 향후 경제 지표 발표와 글로벌 경제 상황을 주기적으로 모니터링하여 투자 전략을 조정하는 것이 중요합니다. \n",
      "\n",
      "이러한 정보를 바탕으로 투자 및 환율 관련 전략을 수립할 때, 전문가의 조언을 추가로 참고하는 것도 좋습니다.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 실시간 환율을 가져오는 함수\n",
    "def get_exchange_rate():\n",
    "    response = requests.get(\"https://api.exchangerate-api.com/v4/latest/USD\")\n",
    "    data = response.json()\n",
    "    return f\"1달러 = {data['rates']['KRW']}원\"\n",
    "\n",
    "# Partial Prompt 활용\n",
    "prompt = PromptTemplate(\n",
    "    template=\"현재 {info} 기준으로 환율 정보를 알려드립니다. 이에 대한 분석을 제공해 주세요.\",\n",
    "    input_variables=[],  # 사용자 입력 없음\n",
    "    partial_variables={\"info\": get_exchange_rate()}  # API에서 가져온 데이터 자동 반영\n",
    ")\n",
    "\n",
    "# LLM 모델 설정\n",
    "#llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.0)\n",
    "\n",
    "# 모델에 프롬프트 전달 및 응답 받기\n",
    "response = llm.invoke(prompt.format())\n",
    "\n",
    "# 결과 출력\n",
    "print(\" 프롬프트:\", prompt.format())\n",
    "print(\" 모델 응답:\", response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mylangchain-app-75wTJiYg-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
